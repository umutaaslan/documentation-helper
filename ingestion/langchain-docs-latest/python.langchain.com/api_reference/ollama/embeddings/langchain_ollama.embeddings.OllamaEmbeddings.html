
<!DOCTYPE html>

<html data-content_root="../../" lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/><meta content="width=device-width, initial-scale=1" name="viewport"/>
<!-- Google tag (gtag.js) -->
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-9B66JQQH2F"></script>
<script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'G-9B66JQQH2F');
    </script>
<title>OllamaEmbeddings â€” ðŸ¦œðŸ”— LangChain  documentation</title>
<script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
<!--
    this give us a css class that will be invisible only if js is disabled
  -->
<noscript>
<style>
      .pst-js-only { display: none !important; }

    </style>
</noscript>
<!-- Loaded before other Sphinx assets -->
<link href="../../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet"/>
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet"/>
<link href="../../_static/pygments.css?v=8f2a1f02" rel="stylesheet" type="text/css"/>
<link href="../../_static/autodoc_pydantic.css" rel="stylesheet" type="text/css"/>
<link href="../../_static/copybutton.css?v=76b2166b" rel="stylesheet" type="text/css"/>
<link href="../../_static/sphinx-design.min.css?v=95c83b7e" rel="stylesheet" type="text/css"/>
<link href="../../_static/css/custom.css?v=8e9fa5b3" rel="stylesheet" type="text/css"/>
<!-- So that users can add custom icons -->
<script src="../../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
<!-- Pre-loaded scripts that we'll load fully later -->
<link as="script" href="../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" rel="preload"/>
<link as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" rel="preload"/>
<script src="../../_static/documentation_options.js?v=3b5cce75"></script>
<script src="../../_static/doctools.js?v=9bcbadda"></script>
<script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
<script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
<script src="../../_static/copybutton.js?v=f281be69"></script>
<script src="../../_static/design-tabs.js?v=f930bc37"></script>
<script>DOCUMENTATION_OPTIONS.pagename = 'ollama/embeddings/langchain_ollama.embeddings.OllamaEmbeddings';</script>
<link href="../../_static/favicon.png" rel="icon"/>
<link href="../../search.html" rel="search" title="Search"/>
<link href="../llms.html" rel="next" title="llms"/>
<link href="../embeddings.html" rel="prev" title="embeddings"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="en" name="docsearch:language"/>
<meta content="" name="docsearch:version"/>
<meta content="Jul 10, 2025" name="docbuild:last-update"/>
</head>
<body data-bs-root-margin="0px 0px -60%" data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-default-mode="" data-offset="180">
<div class="skip-link d-print-none" id="pst-skip-link"><a href="#main-content">Skip to main content</a></div>
<div id="pst-scroll-pixel-helper"></div>
<button class="btn rounded-pill" id="pst-back-to-top" type="button">
<i class="fa-solid fa-arrow-up"></i>Back to top</button>
<dialog id="pst-search-dialog">
<form action="../../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="fa-solid fa-magnifying-glass"></i>
<input aria-label="Search" autocapitalize="off" autocomplete="off" autocorrect="off" class="form-control" name="q" placeholder="Search" spellcheck="false" type="search"/>
<span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</dialog>
<div class="pst-async-banner-revealer d-none">
<aside aria-label="Version warning" class="d-none d-print-none" id="bd-header-version-warning"></aside>
</div>
<header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
<button aria-label="Site navigation" class="pst-navbar-icon sidebar-toggle primary-toggle">
<span class="fa-solid fa-bars"></span>
</button>
<div class="navbar-header-items__start">
<div class="navbar-item">
<a class="navbar-brand logo" href="../../index.html">
<img alt="ðŸ¦œðŸ”— LangChain  documentation - Home" class="logo__image only-light" src="../../_static/wordmark-api.svg"/>
<img alt="ðŸ¦œðŸ”— LangChain  documentation - Home" class="logo__image only-dark pst-js-only" src="../../_static/wordmark-api-dark.svg"/>
</a></div>
</div>
<div class="navbar-header-items">
<div class="me-auto navbar-header-items__center">
<div class="navbar-item">
<nav>
<ul class="bd-navbar-elements navbar-nav">
<li class="nav-item current active">
<a class="nav-link nav-internal" href="../../reference.html">
    Reference
  </a>
</li>
</ul>
</nav></div>
</div>
<div class="navbar-header-items__end">
<div class="navbar-item navbar-persistent--container">
<form action="../../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="fa-solid fa-magnifying-glass"></i>
<input aria-label="Search" autocapitalize="off" autocomplete="off" autocorrect="off" class="form-control" name="q" placeholder="Search" spellcheck="false" type="search"/>
<span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
<div class="navbar-item"><!-- This will display a link to LangChain docs -->
<head>
<style>
        .text-link {
            text-decoration: none; /* Remove underline */
            color: inherit;        /* Inherit color from parent element */
        }
    </style>
</head>
<body>
<a class="text-link" href="https://python.langchain.com/">Docs</a>
</body></div>
<div class="navbar-item">
<button aria-label="Color mode" class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" data-bs-placement="bottom" data-bs-title="Color mode" data-bs-toggle="tooltip">
<i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light" title="Light"></i>
<i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark" title="Dark"></i>
<i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto" title="System Settings"></i>
</button></div>
<div class="navbar-item"><ul aria-label="Quick Links" class="navbar-icon-links">
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://github.com/langchain-ai/langchain" rel="noopener" target="_blank" title="GitHub"><i aria-hidden="true" class="fa-brands fa-square-github fa-lg"></i>
<span class="sr-only">GitHub</span></a>
</li>
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://twitter.com/langchainai" rel="noopener" target="_blank" title="X / Twitter"><i aria-hidden="true" class="fab fa-twitter-square fa-lg"></i>
<span class="sr-only">X / Twitter</span></a>
</li>
</ul></div>
</div>
</div>
<div class="navbar-persistent--mobile">
<form action="../../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="fa-solid fa-magnifying-glass"></i>
<input aria-label="Search" autocapitalize="off" autocomplete="off" autocorrect="off" class="form-control" name="q" placeholder="Search" spellcheck="false" type="search"/>
<span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
<button aria-label="On this page" class="pst-navbar-icon sidebar-toggle secondary-toggle">
<span class="fa-solid fa-outdent"></span>
</button>
</div>
</header>
<div class="bd-container">
<div class="bd-container__inner bd-page-width">
<dialog id="pst-primary-sidebar-modal"></dialog>
<div class="bd-sidebar-primary bd-sidebar" id="pst-primary-sidebar">
<div class="sidebar-header-items sidebar-primary__section">
<div class="sidebar-header-items__center">
<div class="navbar-item">
<nav>
<ul class="bd-navbar-elements navbar-nav">
<li class="nav-item current active">
<a class="nav-link nav-internal" href="../../reference.html">
    Reference
  </a>
</li>
</ul>
</nav></div>
</div>
<div class="sidebar-header-items__end">
<div class="navbar-item"><!-- This will display a link to LangChain docs -->
<head>
<style>
        .text-link {
            text-decoration: none; /* Remove underline */
            color: inherit;        /* Inherit color from parent element */
        }
    </style>
</head>
<body>
<a class="text-link" href="https://python.langchain.com/">Docs</a>
</body></div>
<div class="navbar-item">
<button aria-label="Color mode" class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" data-bs-placement="bottom" data-bs-title="Color mode" data-bs-toggle="tooltip">
<i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light" title="Light"></i>
<i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark" title="Dark"></i>
<i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto" title="System Settings"></i>
</button></div>
<div class="navbar-item"><ul aria-label="Quick Links" class="navbar-icon-links">
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://github.com/langchain-ai/langchain" rel="noopener" target="_blank" title="GitHub"><i aria-hidden="true" class="fa-brands fa-square-github fa-lg"></i>
<span class="sr-only">GitHub</span></a>
</li>
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://twitter.com/langchainai" rel="noopener" target="_blank" title="X / Twitter"><i aria-hidden="true" class="fab fa-twitter-square fa-lg"></i>
<span class="sr-only">X / Twitter</span></a>
</li>
</ul></div>
</div>
</div>
<div class="sidebar-primary-items__start sidebar-primary__section">
<div class="sidebar-primary-item">
<nav aria-label="Section Navigation" class="bd-docs-nav bd-links">
<p aria-level="1" class="bd-links__title" role="heading">Section Navigation</p>
<div class="bd-toc-item navbar-nav"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Base packages</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../core/index.html">Core</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../langchain/index.html">Langchain</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../text_splitters/index.html">Text Splitters</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../community/index.html">Community</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../experimental/index.html">Experimental</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Integrations</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../ai21/index.html">AI21</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../anthropic/index.html">Anthropic</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../astradb/index.html">AstraDB</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../aws/index.html">AWS</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../azure_ai/index.html">Azure Ai</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../azure_dynamic_sessions/index.html">Azure Dynamic Sessions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../cerebras/index.html">Cerebras</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../chroma/index.html">Chroma</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../cohere/index.html">Cohere</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../db2/index.html">Db2</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deepseek/index.html">Deepseek</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../elasticsearch/index.html">Elasticsearch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../exa/index.html">Exa</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../fireworks/index.html">Fireworks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../google_community/index.html">Google Community</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../google_genai/index.html">Google GenAI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../google_vertexai/index.html">Google VertexAI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../groq/index.html">Groq</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../huggingface/index.html">Huggingface</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ibm/index.html">IBM</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../milvus/index.html">Milvus</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mistralai/index.html">MistralAI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mongodb/index.html">MongoDB</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../neo4j/index.html">Neo4J</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../nomic/index.html">Nomic</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../nvidia_ai_endpoints/index.html">Nvidia Ai Endpoints</a></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../index.html">Ollama</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../chat_models.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">chat_models</span></code></a></li>
<li class="toctree-l2 current active has-children"><a class="reference internal" href="../embeddings.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">embeddings</span></code></a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l3 current active"><a class="current reference internal" href="#">OllamaEmbeddings</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../llms.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">llms</span></code></a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../../openai/index.html">OpenAI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../perplexity/index.html">Perplexity</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../pinecone/index.html">Pinecone</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../postgres/index.html">Postgres</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../prompty/index.html">Prompty</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../qdrant/index.html">Qdrant</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../redis/index.html">Redis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../sema4/index.html">Sema4</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../snowflake/index.html">Snowflake</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../sqlserver/index.html">Sqlserver</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../standard_tests/index.html">Standard Tests</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tavily/index.html">Tavily</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../together/index.html">Together</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../unstructured/index.html">Unstructured</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../upstage/index.html">Upstage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../weaviate/index.html">Weaviate</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../xai/index.html">XAI</a></li>
</ul>
</div>
</nav></div>
</div>
<div class="sidebar-primary-items__end sidebar-primary__section">
<div class="sidebar-primary-item">
<div class="flat" data-ea-manual="true" data-ea-publisher="readthedocs" data-ea-type="readthedocs-sidebar" id="ethical-ad-placement">
</div></div>
</div>
</div>
<main class="bd-main" id="main-content" role="main">
<div class="bd-content">
<div class="bd-article-container">
<div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
<div class="header-article-items__start">
<div class="header-article-item">
<nav aria-label="Breadcrumb" class="d-print-none">
<ul class="bd-breadcrumbs">
<li class="breadcrumb-item breadcrumb-home">
<a aria-label="Home" class="nav-link" href="../../index.html">
<i class="fa-solid fa-home"></i>
</a>
</li>
<li class="breadcrumb-item"><a class="nav-link" href="../../reference.html">LangChain Python API Reference</a></li>
<li class="breadcrumb-item"><a class="nav-link" href="../index.html">langchain-ollama: 0.3.4</a></li>
<li class="breadcrumb-item"><a class="nav-link" href="../embeddings.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">embeddings</span></code></a></li>
<li aria-current="page" class="breadcrumb-item active"><span class="ellipsis">OllamaEmbeddings</span></li>
</ul>
</nav>
</div>
</div>
</div>
</div>
<div id="searchbox"></div>
<article class="bd-article">
<section id="ollamaembeddings">
<h1>OllamaEmbeddings<a class="headerlink" href="#ollamaembeddings" title="Link to this heading">#</a></h1>
<dl class="py class pydantic_model">
<dt class="sig sig-object py" id="langchain_ollama.embeddings.OllamaEmbeddings">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">langchain_ollama.embeddings.</span></span><span class="sig-name descname"><span class="pre">OllamaEmbeddings</span></span><a class="reference internal" href="../../_modules/langchain_ollama/embeddings.html#OllamaEmbeddings"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain_ollama.embeddings.OllamaEmbeddings" title="Link to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">BaseModel</span></code>, <a class="reference internal" href="../../core/embeddings/langchain_core.embeddings.embeddings.Embeddings.html#langchain_core.embeddings.embeddings.Embeddings" title="langchain_core.embeddings.embeddings.Embeddings"><code class="xref py py-class docutils literal notranslate"><span class="pre">Embeddings</span></code></a></p>
<p>Ollama embedding model integration.</p>
<dl>
<dt>Set up a local Ollama instance:</dt><dd><p>Install the Ollama package and set up a local Ollama instance
using the instructions here: <a class="github reference external" href="https://github.com/ollama/ollama">ollama/ollama</a> .</p>
<p>You will need to choose a model to serve.</p>
<p>You can view a list of available models via the model library (<a class="reference external" href="https://ollama.com/library">https://ollama.com/library</a>).</p>
<p>To fetch a model from the Ollama model library use <code class="docutils literal notranslate"><span class="pre">ollama</span> <span class="pre">pull</span> <span class="pre">&lt;name-of-model&gt;</span></code>.</p>
<p>For example, to pull the llama3 model:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>ollama<span class="w"> </span>pull<span class="w"> </span>llama3
</pre></div>
</div>
<p>This will download the default tagged version of the model.
Typically, the default points to the latest, smallest sized-parameter model.</p>
<ul class="simple">
<li><p>On Mac, the models will be downloaded to ~/.ollama/models</p></li>
<li><p>On Linux (or WSL), the models will be stored at /usr/share/ollama/.ollama/models</p></li>
</ul>
<p>You can specify the exact version of the model of interest
as such <code class="docutils literal notranslate"><span class="pre">ollama</span> <span class="pre">pull</span> <span class="pre">vicuna:13b-v1.5-16k-q4_0</span></code>.</p>
<p>To view pulled models:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>ollama<span class="w"> </span>list
</pre></div>
</div>
<p>To start serving:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>ollama<span class="w"> </span>serve
</pre></div>
</div>
<p>View the Ollama documentation for more commands.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>ollama<span class="w"> </span><span class="nb">help</span>
</pre></div>
</div>
</dd>
<dt>Install the langchain-ollama integration package:</dt><dd><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span>-U<span class="w"> </span>langchain_ollama
</pre></div>
</div>
</dd>
<dt>Key init args â€” completion params:</dt><dd><dl class="simple">
<dt>model: str</dt><dd><p>Name of Ollama model to use.</p>
</dd>
<dt>base_url: Optional[str]</dt><dd><p>Base url the model is hosted under.</p>
</dd>
</dl>
</dd>
</dl>
<p>See full list of supported init args and their descriptions in the params section.</p>
<dl>
<dt>Instantiate:</dt><dd><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">langchain_ollama</span><span class="w"> </span><span class="kn">import</span> <span class="n">OllamaEmbeddings</span>

<span class="n">embed</span> <span class="o">=</span> <span class="n">OllamaEmbeddings</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="s2">"llama3"</span>
<span class="p">)</span>
</pre></div>
</div>
</dd>
<dt>Embed single text:</dt><dd><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">input_text</span> <span class="o">=</span> <span class="s2">"The meaning of life is 42"</span>
<span class="n">vector</span> <span class="o">=</span> <span class="n">embed</span><span class="o">.</span><span class="n">embed_query</span><span class="p">(</span><span class="n">input_text</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">vector</span><span class="p">[:</span><span class="mi">3</span><span class="p">])</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="o">-</span><span class="mf">0.024603435769677162</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.007543657906353474</span><span class="p">,</span> <span class="mf">0.0039630369283258915</span><span class="p">]</span>
</pre></div>
</div>
</dd>
<dt>Embed multiple texts:</dt><dd><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">input_texts</span> <span class="o">=</span> <span class="p">[</span><span class="s2">"Document 1..."</span><span class="p">,</span> <span class="s2">"Document 2..."</span><span class="p">]</span>
<span class="n">vectors</span> <span class="o">=</span> <span class="n">embed</span><span class="o">.</span><span class="n">embed_documents</span><span class="p">(</span><span class="n">input_texts</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">vectors</span><span class="p">))</span>
<span class="c1"># The first 3 coordinates for the first vector</span>
<span class="nb">print</span><span class="p">(</span><span class="n">vectors</span><span class="p">[</span><span class="mi">0</span><span class="p">][:</span><span class="mi">3</span><span class="p">])</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="mi">2</span>
<span class="p">[</span><span class="o">-</span><span class="mf">0.024603435769677162</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.007543657906353474</span><span class="p">,</span> <span class="mf">0.0039630369283258915</span><span class="p">]</span>
</pre></div>
</div>
</dd>
<dt>Async:</dt><dd><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">vector</span> <span class="o">=</span> <span class="k">await</span> <span class="n">embed</span><span class="o">.</span><span class="n">aembed_query</span><span class="p">(</span><span class="n">input_text</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">vector</span><span class="p">[:</span><span class="mi">3</span><span class="p">])</span>

<span class="c1"># multiple:</span>
<span class="c1"># await embed.aembed_documents(input_texts)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="o">-</span><span class="mf">0.009100092574954033</span><span class="p">,</span> <span class="mf">0.005071679595857859</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0029193938244134188</span><span class="p">]</span>
</pre></div>
</div>
</dd>
</dl>
<p>Create a new model by parsing and validating input data from keyword arguments.</p>
<p>Raises [<cite>ValidationError</cite>][pydantic_core.ValidationError] if the input data cannot be
validated to form a valid model.</p>
<p><cite>self</cite> is explicitly positional-only to allow <cite>self</cite> as a field name.</p>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_ollama.embeddings.OllamaEmbeddings.async_client_kwargs">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">async_client_kwargs</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">dict</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">{}</span></em><a class="headerlink" href="#langchain_ollama.embeddings.OllamaEmbeddings.async_client_kwargs" title="Link to this definition">#</a></dt>
<dd><p>Additional kwargs to merge with client_kwargs before passing to the httpx
AsyncClient.</p>
<p>For a full list of the params, see the <a class="reference external" href="https://www.python-httpx.org/api/#asyncclient">HTTPX documentation</a>.</p>
</dd></dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_ollama.embeddings.OllamaEmbeddings.base_url">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">base_url</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain_ollama.embeddings.OllamaEmbeddings.base_url" title="Link to this definition">#</a></dt>
<dd><p>Base url the model is hosted under.</p>
</dd></dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_ollama.embeddings.OllamaEmbeddings.client_kwargs">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">client_kwargs</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">dict</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">{}</span></em><a class="headerlink" href="#langchain_ollama.embeddings.OllamaEmbeddings.client_kwargs" title="Link to this definition">#</a></dt>
<dd><p>Additional kwargs to pass to the httpx clients.
These arguments are passed to both synchronous and async clients.
Use sync_client_kwargs and async_client_kwargs to pass different arguments
to synchronous and asynchronous clients.</p>
</dd></dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_ollama.embeddings.OllamaEmbeddings.keep_alive">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">keep_alive</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain_ollama.embeddings.OllamaEmbeddings.keep_alive" title="Link to this definition">#</a></dt>
<dd><p>controls how long the model will stay loaded into memory
following the request (default: 5m)</p>
</dd></dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_ollama.embeddings.OllamaEmbeddings.mirostat">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">mirostat</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain_ollama.embeddings.OllamaEmbeddings.mirostat" title="Link to this definition">#</a></dt>
<dd><p>Enable Mirostat sampling for controlling perplexity.
(default: 0, 0 = disabled, 1 = Mirostat, 2 = Mirostat 2.0)</p>
</dd></dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_ollama.embeddings.OllamaEmbeddings.mirostat_eta">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">mirostat_eta</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain_ollama.embeddings.OllamaEmbeddings.mirostat_eta" title="Link to this definition">#</a></dt>
<dd><p>Influences how quickly the algorithm responds to feedback
from the generated text. A lower learning rate will result in
slower adjustments, while a higher learning rate will make
the algorithm more responsive. (Default: 0.1)</p>
</dd></dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_ollama.embeddings.OllamaEmbeddings.mirostat_tau">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">mirostat_tau</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain_ollama.embeddings.OllamaEmbeddings.mirostat_tau" title="Link to this definition">#</a></dt>
<dd><p>Controls the balance between coherence and diversity
of the output. A lower value will result in more focused and
coherent text. (Default: 5.0)</p>
</dd></dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_ollama.embeddings.OllamaEmbeddings.model">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><em class="property"> <span class="pre">[Required]</span></em><a class="headerlink" href="#langchain_ollama.embeddings.OllamaEmbeddings.model" title="Link to this definition">#</a></dt>
<dd><p>Model name to use.</p>
</dd></dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_ollama.embeddings.OllamaEmbeddings.num_ctx">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">num_ctx</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain_ollama.embeddings.OllamaEmbeddings.num_ctx" title="Link to this definition">#</a></dt>
<dd><p>Sets the size of the context window used to generate the
next token. (Default: 2048)</p>
</dd></dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_ollama.embeddings.OllamaEmbeddings.num_gpu">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">num_gpu</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain_ollama.embeddings.OllamaEmbeddings.num_gpu" title="Link to this definition">#</a></dt>
<dd><p>The number of GPUs to use. On macOS it defaults to 1 to
enable metal support, 0 to disable.</p>
</dd></dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_ollama.embeddings.OllamaEmbeddings.num_thread">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">num_thread</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain_ollama.embeddings.OllamaEmbeddings.num_thread" title="Link to this definition">#</a></dt>
<dd><p>Sets the number of threads to use during computation.
By default, Ollama will detect this for optimal performance.
It is recommended to set this value to the number of physical
CPU cores your system has (as opposed to the logical number of cores).</p>
</dd></dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_ollama.embeddings.OllamaEmbeddings.repeat_last_n">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">repeat_last_n</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain_ollama.embeddings.OllamaEmbeddings.repeat_last_n" title="Link to this definition">#</a></dt>
<dd><p>Sets how far back for the model to look back to prevent
repetition. (Default: 64, 0 = disabled, -1 = num_ctx)</p>
</dd></dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_ollama.embeddings.OllamaEmbeddings.repeat_penalty">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">repeat_penalty</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain_ollama.embeddings.OllamaEmbeddings.repeat_penalty" title="Link to this definition">#</a></dt>
<dd><p>Sets how strongly to penalize repetitions. A higher value (e.g., 1.5)
will penalize repetitions more strongly, while a lower value (e.g., 0.9)
will be more lenient. (Default: 1.1)</p>
</dd></dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_ollama.embeddings.OllamaEmbeddings.stop">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">stop</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain_ollama.embeddings.OllamaEmbeddings.stop" title="Link to this definition">#</a></dt>
<dd><p>Sets the stop tokens to use.</p>
</dd></dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_ollama.embeddings.OllamaEmbeddings.sync_client_kwargs">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">sync_client_kwargs</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">dict</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">{}</span></em><a class="headerlink" href="#langchain_ollama.embeddings.OllamaEmbeddings.sync_client_kwargs" title="Link to this definition">#</a></dt>
<dd><p>Additional kwargs to merge with client_kwargs before passing to the HTTPX Client.</p>
<p>For a full list of the params, see the <a class="reference external" href="https://www.python-httpx.org/api/#client">HTTPX documentation</a>.</p>
</dd></dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_ollama.embeddings.OllamaEmbeddings.temperature">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">temperature</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain_ollama.embeddings.OllamaEmbeddings.temperature" title="Link to this definition">#</a></dt>
<dd><p>The temperature of the model. Increasing the temperature will
make the model answer more creatively. (Default: 0.8)</p>
</dd></dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_ollama.embeddings.OllamaEmbeddings.tfs_z">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">tfs_z</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain_ollama.embeddings.OllamaEmbeddings.tfs_z" title="Link to this definition">#</a></dt>
<dd><p>Tail free sampling is used to reduce the impact of less probable
tokens from the output. A higher value (e.g., 2.0) will reduce the
impact more, while a value of 1.0 disables this setting. (default: 1)</p>
</dd></dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_ollama.embeddings.OllamaEmbeddings.top_k">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">top_k</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain_ollama.embeddings.OllamaEmbeddings.top_k" title="Link to this definition">#</a></dt>
<dd><p>Reduces the probability of generating nonsense. A higher value (e.g. 100)
will give more diverse answers, while a lower value (e.g. 10)
will be more conservative. (Default: 40)</p>
</dd></dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_ollama.embeddings.OllamaEmbeddings.top_p">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">top_p</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain_ollama.embeddings.OllamaEmbeddings.top_p" title="Link to this definition">#</a></dt>
<dd><p>Works together with top-k. A higher value (e.g., 0.95) will lead
to more diverse text, while a lower value (e.g., 0.5) will
generate more focused and conservative text. (Default: 0.9)</p>
</dd></dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_ollama.embeddings.OllamaEmbeddings.validate_model_on_init">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">validate_model_on_init</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#langchain_ollama.embeddings.OllamaEmbeddings.validate_model_on_init" title="Link to this definition">#</a></dt>
<dd><p>Whether to validate the model exists in ollama locally on initialization.</p>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="langchain_ollama.embeddings.OllamaEmbeddings.aembed_documents">
<em class="property"><span class="k"><span class="pre">async</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">aembed_documents</span></span><span class="sig-paren">(</span>
<dl>
<dd><em class="sig-param"><span class="n"><span class="pre">texts</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>,</dd>
</dl>
<span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">â†’</span> <span class="sig-return-typehint"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../../_modules/langchain_ollama/embeddings.html#OllamaEmbeddings.aembed_documents"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain_ollama.embeddings.OllamaEmbeddings.aembed_documents" title="Link to this definition">#</a></dt>
<dd><p>Embed search docs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>texts</strong> (<em>list</em><em>[</em><em>str</em><em>]</em>)</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>list[list[float]]</p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="langchain_ollama.embeddings.OllamaEmbeddings.aembed_query">
<em class="property"><span class="k"><span class="pre">async</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">aembed_query</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">â†’</span> <span class="sig-return-typehint"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../../_modules/langchain_ollama/embeddings.html#OllamaEmbeddings.aembed_query"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain_ollama.embeddings.OllamaEmbeddings.aembed_query" title="Link to this definition">#</a></dt>
<dd><p>Embed query text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>)</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>list[float]</p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="langchain_ollama.embeddings.OllamaEmbeddings.embed_documents">
<span class="sig-name descname"><span class="pre">embed_documents</span></span><span class="sig-paren">(</span>
<dl>
<dd><em class="sig-param"><span class="n"><span class="pre">texts</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>,</dd>
</dl>
<span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">â†’</span> <span class="sig-return-typehint"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../../_modules/langchain_ollama/embeddings.html#OllamaEmbeddings.embed_documents"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain_ollama.embeddings.OllamaEmbeddings.embed_documents" title="Link to this definition">#</a></dt>
<dd><p>Embed search docs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>texts</strong> (<em>list</em><em>[</em><em>str</em><em>]</em>)</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>list[list[float]]</p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="langchain_ollama.embeddings.OllamaEmbeddings.embed_query">
<span class="sig-name descname"><span class="pre">embed_query</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">â†’</span> <span class="sig-return-typehint"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../../_modules/langchain_ollama/embeddings.html#OllamaEmbeddings.embed_query"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain_ollama.embeddings.OllamaEmbeddings.embed_query" title="Link to this definition">#</a></dt>
<dd><p>Embed query text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>)</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>list[float]</p>
</dd>
</dl>
</dd></dl>
</dd></dl>
<p class="rubric">Examples using OllamaEmbeddings</p>
<ul class="simple">
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/vectorstores/aperturedb/">ApertureDB</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/providers/ollama/">Ollama</a></p></li>
</ul>
</section>
</article>
</div>
<dialog id="pst-secondary-sidebar-modal"></dialog>
<div class="bd-sidebar-secondary bd-toc" id="pst-secondary-sidebar"><div class="sidebar-secondary-items sidebar-secondary__inner">
<div class="sidebar-secondary-item">
<div class="page-toc tocsection onthispage" id="pst-page-navigation-heading-2">
<i class="fa-solid fa-list"></i> On this page
  </div>
<nav aria-labelledby="pst-page-navigation-heading-2" class="bd-toc-nav page-toc">
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_ollama.embeddings.OllamaEmbeddings"><code class="docutils literal notranslate"><span class="pre">OllamaEmbeddings</span></code></a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_ollama.embeddings.OllamaEmbeddings.async_client_kwargs"><code class="docutils literal notranslate"><span class="pre">async_client_kwargs</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_ollama.embeddings.OllamaEmbeddings.base_url"><code class="docutils literal notranslate"><span class="pre">base_url</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_ollama.embeddings.OllamaEmbeddings.client_kwargs"><code class="docutils literal notranslate"><span class="pre">client_kwargs</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_ollama.embeddings.OllamaEmbeddings.keep_alive"><code class="docutils literal notranslate"><span class="pre">keep_alive</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_ollama.embeddings.OllamaEmbeddings.mirostat"><code class="docutils literal notranslate"><span class="pre">mirostat</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_ollama.embeddings.OllamaEmbeddings.mirostat_eta"><code class="docutils literal notranslate"><span class="pre">mirostat_eta</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_ollama.embeddings.OllamaEmbeddings.mirostat_tau"><code class="docutils literal notranslate"><span class="pre">mirostat_tau</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_ollama.embeddings.OllamaEmbeddings.model"><code class="docutils literal notranslate"><span class="pre">model</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_ollama.embeddings.OllamaEmbeddings.num_ctx"><code class="docutils literal notranslate"><span class="pre">num_ctx</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_ollama.embeddings.OllamaEmbeddings.num_gpu"><code class="docutils literal notranslate"><span class="pre">num_gpu</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_ollama.embeddings.OllamaEmbeddings.num_thread"><code class="docutils literal notranslate"><span class="pre">num_thread</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_ollama.embeddings.OllamaEmbeddings.repeat_last_n"><code class="docutils literal notranslate"><span class="pre">repeat_last_n</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_ollama.embeddings.OllamaEmbeddings.repeat_penalty"><code class="docutils literal notranslate"><span class="pre">repeat_penalty</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_ollama.embeddings.OllamaEmbeddings.stop"><code class="docutils literal notranslate"><span class="pre">stop</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_ollama.embeddings.OllamaEmbeddings.sync_client_kwargs"><code class="docutils literal notranslate"><span class="pre">sync_client_kwargs</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_ollama.embeddings.OllamaEmbeddings.temperature"><code class="docutils literal notranslate"><span class="pre">temperature</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_ollama.embeddings.OllamaEmbeddings.tfs_z"><code class="docutils literal notranslate"><span class="pre">tfs_z</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_ollama.embeddings.OllamaEmbeddings.top_k"><code class="docutils literal notranslate"><span class="pre">top_k</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_ollama.embeddings.OllamaEmbeddings.top_p"><code class="docutils literal notranslate"><span class="pre">top_p</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_ollama.embeddings.OllamaEmbeddings.validate_model_on_init"><code class="docutils literal notranslate"><span class="pre">validate_model_on_init</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_ollama.embeddings.OllamaEmbeddings.aembed_documents"><code class="docutils literal notranslate"><span class="pre">aembed_documents()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_ollama.embeddings.OllamaEmbeddings.aembed_query"><code class="docutils literal notranslate"><span class="pre">aembed_query()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_ollama.embeddings.OllamaEmbeddings.embed_documents"><code class="docutils literal notranslate"><span class="pre">embed_documents()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_ollama.embeddings.OllamaEmbeddings.embed_query"><code class="docutils literal notranslate"><span class="pre">embed_query()</span></code></a></li>
</ul>
</li>
</ul>
</nav></div>
</div></div>
</div>
<footer class="bd-footer-content">
</footer>
</main>
</div>
</div>
<!-- Scripts loaded after <body> so the DOM is not blocked -->
<script defer="" src="../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer="" src="../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>
<footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
<div class="footer-items__start">
<div class="footer-item">
<p class="copyright">
    
      Â© Copyright 2025, LangChain Inc.
      <br/>
</p>
</div>
</div>
</div>
</footer>
</body>
</html>