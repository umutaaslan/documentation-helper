<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-default docs-doc-id-integrations/llms/llamacpp" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.4.3">
<title data-rh="true">Llama.cpp | 🦜️🔗 LangChain</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://python.langchain.com/v0.1/img/brand/theme-image.png"><meta data-rh="true" name="twitter:image" content="https://python.langchain.com/v0.1/img/brand/theme-image.png"><meta data-rh="true" property="og:url" content="https://python.langchain.com/v0.1/docs/integrations/llms/llamacpp/"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Llama.cpp | 🦜️🔗 LangChain"><meta data-rh="true" name="description" content="llama-cpp-python is a Python binding for llama.cpp."><meta data-rh="true" property="og:description" content="llama-cpp-python is a Python binding for llama.cpp."><link data-rh="true" rel="icon" href="/v0.1/img/brand/favicon.png"><link data-rh="true" rel="canonical" href="https://python.langchain.com/v0.1/docs/integrations/llms/llamacpp/"><link data-rh="true" rel="alternate" href="https://python.langchain.com/v0.1/docs/integrations/llms/llamacpp/" hreflang="en"><link data-rh="true" rel="alternate" href="https://python.langchain.com/v0.1/docs/integrations/llms/llamacpp/" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://VAU016LAWS-dsn.algolia.net" crossorigin="anonymous"><link rel="search" type="application/opensearchdescription+xml" title="🦜️🔗 LangChain" href="/v0.1/opensearch.xml">


<script src="/v0.1/js/google_analytics.js"></script>
<script src="https://www.googletagmanager.com/gtag/js?id=G-9B66JQQH2F" async></script><link rel="stylesheet" href="/v0.1/assets/css/styles.d4021fd6.css">
<link rel="preload" href="/v0.1/assets/js/runtime~main.1cd6ff7f.js" as="script">
<link rel="preload" href="/v0.1/assets/js/main.524fe94c.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}return t}()||function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();null!==e?t(e):window.matchMedia("(prefers-color-scheme: dark)").matches?t("dark"):(window.matchMedia("(prefers-color-scheme: light)").matches,t("light"))}(),document.documentElement.setAttribute("data-announcement-bar-initially-dismissed",function(){try{return"true"===localStorage.getItem("docusaurus.announcement.dismiss")}catch(t){}return!1}())</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><div class="announcementBar_mb4j" style="background-color:#FF0000;color:#FFFFFF" role="banner"><div class="content_knG7 announcementBarContent_xLdY">This is documentation for LangChain v0.1, which is no longer actively maintained. Check out the docs for the <a href="https://python.langchain.com/docs/introduction">latest version here</a>.</div></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/v0.1/"><div class="navbar__logo"><img src="/v0.1/img/brand/wordmark.png" alt="🦜️🔗 LangChain" class="themedImage_ToTc themedImage--light_HNdA"><img src="/v0.1/img/brand/wordmark-dark.png" alt="🦜️🔗 LangChain" class="themedImage_ToTc themedImage--dark_i4oU"></div></a><a class="navbar__item navbar__link" href="/v0.1/docs/modules/">Components</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/v0.1/docs/integrations/platforms/">Integrations</a><a class="navbar__item navbar__link" href="/v0.1/docs/guides/">Guides</a><a href="https://api.python.langchain.com/en/v0.1/" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">API Reference<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="navbar__item dropdown dropdown--hoverable"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">More</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/v0.1/docs/people/">People</a></li><li><a class="dropdown__link" href="/v0.1/docs/packages/">Versioning</a></li><li><a class="dropdown__link" href="/v0.1/docs/contributing/">Contributing</a></li><li><a class="dropdown__link" href="/v0.1/docs/templates/">Templates</a></li><li><a href="https://github.com/langchain-ai/langchain/blob/master/cookbook/README.md" target="_blank" rel="noopener noreferrer" class="dropdown__link">Cookbooks<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li><a class="dropdown__link" href="/v0.1/docs/additional_resources/tutorials/">Tutorials</a></li><li><a class="dropdown__link" href="/v0.1/docs/additional_resources/youtube/">YouTube</a></li></ul></div></div><div class="navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">v0.1</a><ul class="dropdown__menu"><li><a href="https://python.langchain.com/docs/introduction" target="_blank" rel="noopener noreferrer" class="dropdown__link">Latest<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li><a href="https://python.langchain.com/v0.2/docs/introduction" target="_blank" rel="noopener noreferrer" class="dropdown__link">v0.2<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li><a class="dropdown__link" href="/v0.1/docs/get_started/introduction/">v0.1</a></li></ul></div><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">🦜️🔗</a><ul class="dropdown__menu"><li><a href="https://smith.langchain.com" target="_blank" rel="noopener noreferrer" class="dropdown__link">LangSmith<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li><a href="https://docs.smith.langchain.com/" target="_blank" rel="noopener noreferrer" class="dropdown__link">LangSmith Docs<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li><a href="https://github.com/langchain-ai/langserve" target="_blank" rel="noopener noreferrer" class="dropdown__link">LangServe GitHub<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li><a href="https://github.com/langchain-ai/langchain/tree/master/templates" target="_blank" rel="noopener noreferrer" class="dropdown__link">Templates GitHub<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li><a href="https://templates.langchain.com" target="_blank" rel="noopener noreferrer" class="dropdown__link">Templates Hub<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li><a href="https://smith.langchain.com/hub" target="_blank" rel="noopener noreferrer" class="dropdown__link">LangChain Hub<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li><a href="https://js.langchain.com" target="_blank" rel="noopener noreferrer" class="dropdown__link">JS/TS Docs<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><a href="https://chat.langchain.com" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">💬<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><a href="https://github.com/langchain-ai/langchain" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-github-link" aria-label="GitHub repository"></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search (Command+K)"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20" aria-hidden="true"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0 docsWrapper_BCFX"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docPage__5DB"><aside class="theme-doc-sidebar-container docSidebarContainer_b6E3"><div class="sidebarViewport_Xe31"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG menuWithAnnouncementBar_GW3s"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link" href="/v0.1/docs/integrations/platforms/">Providers</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/platforms/">Providers</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/platforms/anthropic/">Anthropic</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/platforms/aws/">AWS</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/platforms/google/">Google</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/platforms/huggingface/">Hugging Face</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/platforms/microsoft/">Microsoft</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/platforms/openai/">OpenAI</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/v0.1/docs/integrations/providers/">More</a><button aria-label="Toggle the collapsible sidebar category &#x27;More&#x27;" type="button" class="clean-btn menu__caret"></button></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--active" href="/v0.1/docs/integrations/components/">Components</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/v0.1/docs/integrations/chat/">Chat models</a><button aria-label="Toggle the collapsible sidebar category &#x27;Chat models&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" aria-expanded="true" tabindex="0" href="/v0.1/docs/integrations/llms/">LLMs</a><button aria-label="Toggle the collapsible sidebar category &#x27;LLMs&#x27;" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/">LLMs</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/ai21/">AI21 Labs</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/aleph_alpha/">Aleph Alpha</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/alibabacloud_pai_eas_endpoint/">Alibaba Cloud PAI EAS</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/amazon_api_gateway/">Amazon API Gateway</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/anthropic/">Anthropic</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/anyscale/">Anyscale</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/aphrodite/">Aphrodite Engine</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/arcee/">Arcee</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/azure_ml/">Azure ML</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/azure_openai/">Azure OpenAI</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/baichuan/">Baichuan LLM</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/baidu_qianfan_endpoint/">Baidu Qianfan</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/banana/">Banana</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/baseten/">Baseten</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/beam/">Beam</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/bedrock/">Bedrock</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/bittensor/">Bittensor</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/cerebriumai/">CerebriumAI</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/chatglm/">ChatGLM</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/clarifai/">Clarifai</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/cloudflare_workersai/">Cloudflare Workers AI</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/cohere/">Cohere</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/ctransformers/">C Transformers</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/ctranslate2/">CTranslate2</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/databricks/">Databricks</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/deepinfra/">DeepInfra</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/deepsparse/">DeepSparse</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/edenai/">Eden AI</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/exllamav2/">ExLlamaV2</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/fireworks/">Fireworks</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/forefrontai/">ForefrontAI</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/friendli/">Friendli</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/gigachat/">GigaChat</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/google_ai/">Google AI</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/google_vertex_ai_palm/">Google Cloud Vertex AI</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/gooseai/">GooseAI</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/gpt4all/">GPT4All</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/gradient/">Gradient</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/huggingface_endpoint/">Huggingface Endpoints</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/huggingface_pipelines/">Hugging Face Local Pipelines</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/ibm_watsonx/">IBM watsonx.ai</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/ipex_llm/">IPEX-LLM</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/javelin/">Javelin AI Gateway Tutorial</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/jsonformer_experimental/">JSONFormer</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/koboldai/">KoboldAI API</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/konko/">Konko</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/layerup_security/">Layerup Security</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/v0.1/docs/integrations/llms/llamacpp/">Llama.cpp</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/llamafile/">Llamafile</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/llm_caching/">LLM Caching integrations</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/lmformatenforcer_experimental/">LM Format Enforcer</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/manifest/">Manifest</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/minimax/">Minimax</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/mlx_pipelines/">MLX Local Pipelines</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/modal/">Modal</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/moonshot/">MoonshotChat</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/mosaicml/">MosaicML</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/nlpcloud/">NLP Cloud</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/oci_generative_ai/">oci_generative_ai</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/oci_model_deployment_endpoint/">OCI Data Science Model Deployment Endpoint</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/octoai/">OctoAI</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/ollama/">Ollama</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/opaqueprompts/">OpaquePrompts</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/openai/">OpenAI</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/openllm/">OpenLLM</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/openlm/">OpenLM</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/openvino/">OpenVINO</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/petals/">Petals</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/pipelineai/">PipelineAI</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/predibase/">Predibase</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/predictionguard/">Prediction Guard</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/promptlayer_openai/">PromptLayer OpenAI</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/rellm_experimental/">RELLM</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/replicate/">Replicate</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/runhouse/">Runhouse</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/sagemaker/">SageMakerEndpoint</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/sambanova/">SambaNova</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/solar/">Solar</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/sparkllm/">SparkLLM</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/stochasticai/">StochasticAI</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/symblai_nebula/">Nebula (Symbl.ai)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/textgen/">TextGen</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/titan_takeoff/">Titan Takeoff</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/together/">Together AI</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/tongyi/">Tongyi Qwen</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/vllm/">vLLM</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/volcengine_maas/">Volc Engine Maas</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/weight_only_quantization/">Intel Weight-Only Quantization</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/writer/">Writer</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/xinference/">Xorbits Inference (Xinference)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/yandex/">YandexGPT</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v0.1/docs/integrations/llms/yuan2/">Yuan2.0</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/v0.1/docs/integrations/text_embedding/">Embedding models</a><button aria-label="Toggle the collapsible sidebar category &#x27;Embedding models&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/v0.1/docs/integrations/document_loaders/">Document loaders</a><button aria-label="Toggle the collapsible sidebar category &#x27;Document loaders&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/v0.1/docs/integrations/document_transformers/">Document transformers</a><button aria-label="Toggle the collapsible sidebar category &#x27;Document transformers&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/v0.1/docs/integrations/vectorstores/">Vector stores</a><button aria-label="Toggle the collapsible sidebar category &#x27;Vector stores&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/v0.1/docs/integrations/retrievers/">Retrievers</a><button aria-label="Toggle the collapsible sidebar category &#x27;Retrievers&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/v0.1/docs/integrations/tools/">Tools</a><button aria-label="Toggle the collapsible sidebar category &#x27;Tools&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/v0.1/docs/integrations/toolkits/">Toolkits</a><button aria-label="Toggle the collapsible sidebar category &#x27;Toolkits&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/v0.1/docs/integrations/memory/">Memory</a><button aria-label="Toggle the collapsible sidebar category &#x27;Memory&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/v0.1/docs/integrations/graphs/">Graphs</a><button aria-label="Toggle the collapsible sidebar category &#x27;Graphs&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/v0.1/docs/integrations/callbacks/">Callbacks</a><button aria-label="Toggle the collapsible sidebar category &#x27;Callbacks&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/v0.1/docs/integrations/chat_loaders/">Chat loaders</a><button aria-label="Toggle the collapsible sidebar category &#x27;Chat loaders&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/v0.1/docs/integrations/adapters/">Adapters</a><button aria-label="Toggle the collapsible sidebar category &#x27;Adapters&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/v0.1/docs/integrations/stores/">Stores</a><button aria-label="Toggle the collapsible sidebar category &#x27;Stores&#x27;" type="button" class="clean-btn menu__caret"></button></div></li></ul></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_gTbr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="theme-doc-version-banner alert alert--warning margin-bottom--md" role="alert"><div>This is documentation for <!-- -->LangChain<!-- --> <b>v0.1</b>, which is no longer actively maintained.</div><div class="margin-top--md">For the current stable version, see <b><a href="https://python.langchain.com/docs/integrations/llms/llamacpp/" target="_blank" rel="noopener noreferrer">this version</a></b> (<!-- -->Latest<!-- -->).</div></div><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/v0.1/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/v0.1/docs/integrations/components/"><span itemprop="name">Components</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/v0.1/docs/integrations/llms/"><span itemprop="name">LLMs</span></a><meta itemprop="position" content="2"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Llama.cpp</span><meta itemprop="position" content="3"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>Llama.cpp</h1><p><a href="https://github.com/abetlen/llama-cpp-python" target="_blank" rel="noopener noreferrer">llama-cpp-python</a> is a Python binding for <a href="https://github.com/ggerganov/llama.cpp" target="_blank" rel="noopener noreferrer">llama.cpp</a>.</p><p>It supports inference for <a href="https://github.com/ggerganov/llama.cpp#description" target="_blank" rel="noopener noreferrer">many LLMs</a> models, which can be accessed on <a href="https://huggingface.co/TheBloke" target="_blank" rel="noopener noreferrer">Hugging Face</a>.</p><p>This notebook goes over how to run <code>llama-cpp-python</code> within LangChain.</p><p><strong>Note: new versions of <code>llama-cpp-python</code> use GGUF model files (see <a href="https://github.com/abetlen/llama-cpp-python/pull/633" target="_blank" rel="noopener noreferrer">here</a>).</strong></p><p>This is a breaking change.</p><p>To convert existing GGML models to GGUF you can run the following in <a href="https://github.com/ggerganov/llama.cpp" target="_blank" rel="noopener noreferrer">llama.cpp</a>:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">python ./convert-llama-ggmlv3-to-gguf.py --eps 1e-5 --input models/openorca-platypus2-13b.ggmlv3.q4_0.bin --output models/openorca-platypus2-13b.gguf.q4_0.bin</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h2 class="anchor anchorWithStickyNavbar_LWe7" id="installation">Installation<a href="#installation" class="hash-link" aria-label="Direct link to Installation" title="Direct link to Installation">​</a></h2><p>There are different options on how to install the llama-cpp package: </p><ul><li>CPU usage</li><li>CPU + GPU (using one of many BLAS backends)</li><li>Metal GPU (MacOS with Apple Silicon Chip) </li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="cpu-only-installation">CPU only installation<a href="#cpu-only-installation" class="hash-link" aria-label="Direct link to CPU only installation" title="Direct link to CPU only installation">​</a></h3><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token operator" style="color:rgb(0, 0, 0)">%</span><span class="token plain">pip install </span><span class="token operator" style="color:rgb(0, 0, 0)">-</span><span class="token operator" style="color:rgb(0, 0, 0)">-</span><span class="token plain">upgrade </span><span class="token operator" style="color:rgb(0, 0, 0)">-</span><span class="token operator" style="color:rgb(0, 0, 0)">-</span><span class="token plain">quiet  llama</span><span class="token operator" style="color:rgb(0, 0, 0)">-</span><span class="token plain">cpp</span><span class="token operator" style="color:rgb(0, 0, 0)">-</span><span class="token plain">python</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h3 class="anchor anchorWithStickyNavbar_LWe7" id="installation-with-openblas--cublas--clblast">Installation with OpenBLAS / cuBLAS / CLBlast<a href="#installation-with-openblas--cublas--clblast" class="hash-link" aria-label="Direct link to Installation with OpenBLAS / cuBLAS / CLBlast" title="Direct link to Installation with OpenBLAS / cuBLAS / CLBlast">​</a></h3><p><code>llama.cpp</code> supports multiple BLAS backends for faster processing. Use the <code>FORCE_CMAKE=1</code> environment variable to force the use of cmake and install the pip package for the desired BLAS backend (<a href="https://github.com/abetlen/llama-cpp-python#installation-with-openblas--cublas--clblast" target="_blank" rel="noopener noreferrer">source</a>).</p><p>Example installation with cuBLAS backend:</p><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">!CMAKE_ARGS</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token string" style="color:rgb(163, 21, 21)">&quot;-DLLAMA_CUBLAS=on&quot;</span><span class="token plain"> FORCE_CMAKE</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token number" style="color:rgb(9, 134, 88)">1</span><span class="token plain"> pip install llama</span><span class="token operator" style="color:rgb(0, 0, 0)">-</span><span class="token plain">cpp</span><span class="token operator" style="color:rgb(0, 0, 0)">-</span><span class="token plain">python</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p><strong>IMPORTANT</strong>: If you have already installed the CPU only version of the package, you need to reinstall it from scratch. Consider the following command: </p><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">!CMAKE_ARGS</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token string" style="color:rgb(163, 21, 21)">&quot;-DLLAMA_CUBLAS=on&quot;</span><span class="token plain"> FORCE_CMAKE</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token number" style="color:rgb(9, 134, 88)">1</span><span class="token plain"> pip install </span><span class="token operator" style="color:rgb(0, 0, 0)">-</span><span class="token operator" style="color:rgb(0, 0, 0)">-</span><span class="token plain">upgrade </span><span class="token operator" style="color:rgb(0, 0, 0)">-</span><span class="token operator" style="color:rgb(0, 0, 0)">-</span><span class="token plain">force</span><span class="token operator" style="color:rgb(0, 0, 0)">-</span><span class="token plain">reinstall llama</span><span class="token operator" style="color:rgb(0, 0, 0)">-</span><span class="token plain">cpp</span><span class="token operator" style="color:rgb(0, 0, 0)">-</span><span class="token plain">python </span><span class="token operator" style="color:rgb(0, 0, 0)">-</span><span class="token operator" style="color:rgb(0, 0, 0)">-</span><span class="token plain">no</span><span class="token operator" style="color:rgb(0, 0, 0)">-</span><span class="token plain">cache</span><span class="token operator" style="color:rgb(0, 0, 0)">-</span><span class="token builtin" style="color:rgb(0, 112, 193)">dir</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h3 class="anchor anchorWithStickyNavbar_LWe7" id="installation-with-metal">Installation with Metal<a href="#installation-with-metal" class="hash-link" aria-label="Direct link to Installation with Metal" title="Direct link to Installation with Metal">​</a></h3><p><code>llama.cpp</code> supports Apple silicon first-class citizen - optimized via ARM NEON, Accelerate and Metal frameworks. Use the <code>FORCE_CMAKE=1</code> environment variable to force the use of cmake and install the pip package for the Metal support (<a href="https://github.com/abetlen/llama-cpp-python/blob/main/docs/install/macos.md" target="_blank" rel="noopener noreferrer">source</a>).</p><p>Example installation with Metal Support:</p><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">!CMAKE_ARGS</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token string" style="color:rgb(163, 21, 21)">&quot;-DLLAMA_METAL=on&quot;</span><span class="token plain"> FORCE_CMAKE</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token number" style="color:rgb(9, 134, 88)">1</span><span class="token plain"> pip install llama</span><span class="token operator" style="color:rgb(0, 0, 0)">-</span><span class="token plain">cpp</span><span class="token operator" style="color:rgb(0, 0, 0)">-</span><span class="token plain">python</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p><strong>IMPORTANT</strong>: If you have already installed a cpu only version of the package, you need to reinstall it from scratch: consider the following command: </p><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">!CMAKE_ARGS</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token string" style="color:rgb(163, 21, 21)">&quot;-DLLAMA_METAL=on&quot;</span><span class="token plain"> FORCE_CMAKE</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token number" style="color:rgb(9, 134, 88)">1</span><span class="token plain"> pip install </span><span class="token operator" style="color:rgb(0, 0, 0)">-</span><span class="token operator" style="color:rgb(0, 0, 0)">-</span><span class="token plain">upgrade </span><span class="token operator" style="color:rgb(0, 0, 0)">-</span><span class="token operator" style="color:rgb(0, 0, 0)">-</span><span class="token plain">force</span><span class="token operator" style="color:rgb(0, 0, 0)">-</span><span class="token plain">reinstall llama</span><span class="token operator" style="color:rgb(0, 0, 0)">-</span><span class="token plain">cpp</span><span class="token operator" style="color:rgb(0, 0, 0)">-</span><span class="token plain">python </span><span class="token operator" style="color:rgb(0, 0, 0)">-</span><span class="token operator" style="color:rgb(0, 0, 0)">-</span><span class="token plain">no</span><span class="token operator" style="color:rgb(0, 0, 0)">-</span><span class="token plain">cache</span><span class="token operator" style="color:rgb(0, 0, 0)">-</span><span class="token builtin" style="color:rgb(0, 112, 193)">dir</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h3 class="anchor anchorWithStickyNavbar_LWe7" id="installation-with-windows">Installation with Windows<a href="#installation-with-windows" class="hash-link" aria-label="Direct link to Installation with Windows" title="Direct link to Installation with Windows">​</a></h3><p>It is stable to install the <code>llama-cpp-python</code> library by compiling from the source. You can follow most of the instructions in the repository itself but there are some windows specific instructions which might be useful.</p><p>Requirements to install the <code>llama-cpp-python</code>,</p><ul><li>git</li><li>python</li><li>cmake</li><li>Visual Studio Community (make sure you install this with the following settings)<ul><li>Desktop development with C++</li><li>Python development</li><li>Linux embedded development with C++</li></ul></li></ul><ol><li>Clone git repository recursively to get <code>llama.cpp</code> submodule as well </li></ol><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">git clone --recursive -j8 https://github.com/abetlen/llama-cpp-python.git</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ol start="2"><li>Open up a command Prompt and set the following environment variables.</li></ol><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">set FORCE_CMAKE=1</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">set CMAKE_ARGS=-DLLAMA_CUBLAS=OFF</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>If you have an NVIDIA GPU make sure <code>DLLAMA_CUBLAS</code> is set to <code>ON</code></p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="compiling-and-installing">Compiling and installing<a href="#compiling-and-installing" class="hash-link" aria-label="Direct link to Compiling and installing" title="Direct link to Compiling and installing">​</a></h4><p>Now you can <code>cd</code> into the <code>llama-cpp-python</code> directory and install the package</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">python -m pip install -e .</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p><strong>IMPORTANT</strong>: If you have already installed a cpu only version of the package, you need to reinstall it from scratch: consider the following command: </p><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">!python </span><span class="token operator" style="color:rgb(0, 0, 0)">-</span><span class="token plain">m pip install </span><span class="token operator" style="color:rgb(0, 0, 0)">-</span><span class="token plain">e </span><span class="token punctuation" style="color:rgb(4, 81, 165)">.</span><span class="token plain"> </span><span class="token operator" style="color:rgb(0, 0, 0)">-</span><span class="token operator" style="color:rgb(0, 0, 0)">-</span><span class="token plain">force</span><span class="token operator" style="color:rgb(0, 0, 0)">-</span><span class="token plain">reinstall </span><span class="token operator" style="color:rgb(0, 0, 0)">-</span><span class="token operator" style="color:rgb(0, 0, 0)">-</span><span class="token plain">no</span><span class="token operator" style="color:rgb(0, 0, 0)">-</span><span class="token plain">cache</span><span class="token operator" style="color:rgb(0, 0, 0)">-</span><span class="token builtin" style="color:rgb(0, 112, 193)">dir</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h2 class="anchor anchorWithStickyNavbar_LWe7" id="usage">Usage<a href="#usage" class="hash-link" aria-label="Direct link to Usage" title="Direct link to Usage">​</a></h2><p>Make sure you are following all instructions to <a href="https://github.com/ggerganov/llama.cpp" target="_blank" rel="noopener noreferrer">install all necessary model files</a>.</p><p>You don&#x27;t need an <code>API_TOKEN</code> as you will run the LLM locally.</p><p>It is worth understanding which models are suitable to be used on the desired machine.</p><p><a href="https://huggingface.co/TheBloke" target="_blank" rel="noopener noreferrer">TheBloke&#x27;s</a> Hugging Face models have a <code>Provided files</code> section that exposes the RAM required to run models of different quantisation sizes and methods (eg: <a href="https://huggingface.co/TheBloke/Llama-2-7b-Chat-GGUF#provided-files" target="_blank" rel="noopener noreferrer">Llama2-7B-Chat-GGUF</a>).</p><p>This <a href="https://github.com/facebookresearch/llama/issues/425" target="_blank" rel="noopener noreferrer">github issue</a> is also relevant to find the right model for your machine.</p><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token keyword" style="color:rgb(0, 0, 255)">from</span><span class="token plain"> langchain_community</span><span class="token punctuation" style="color:rgb(4, 81, 165)">.</span><span class="token plain">llms </span><span class="token keyword" style="color:rgb(0, 0, 255)">import</span><span class="token plain"> LlamaCpp</span><br></span><span class="token-line" style="color:#000000"><span class="token plain"></span><span class="token keyword" style="color:rgb(0, 0, 255)">from</span><span class="token plain"> langchain_core</span><span class="token punctuation" style="color:rgb(4, 81, 165)">.</span><span class="token plain">callbacks </span><span class="token keyword" style="color:rgb(0, 0, 255)">import</span><span class="token plain"> CallbackManager</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"> StreamingStdOutCallbackHandler</span><br></span><span class="token-line" style="color:#000000"><span class="token plain"></span><span class="token keyword" style="color:rgb(0, 0, 255)">from</span><span class="token plain"> langchain_core</span><span class="token punctuation" style="color:rgb(4, 81, 165)">.</span><span class="token plain">prompts </span><span class="token keyword" style="color:rgb(0, 0, 255)">import</span><span class="token plain"> PromptTemplate</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><div style="padding-top:1.3rem;background:var(--prism-background-color);color:var(--prism-color);margin-top:calc(-1 * var(--ifm-leading) - 5px);margin-bottom:var(--ifm-leading);box-shadow:var(--ifm-global-shadow-lw);border-bottom-left-radius:var(--ifm-code-border-radius);border-bottom-right-radius:var(--ifm-code-border-radius)"><h4 style="padding-left:0.65rem;margin-bottom:0.45rem">API Reference:</h4><ul style="padding-bottom:1rem"><li><a href="https://api.python.langchain.com/en/latest/llms/langchain_community.llms.llamacpp.LlamaCpp.html"><span>LlamaCpp</span></a></li><li><a href="https://api.python.langchain.com/en/latest/callbacks/langchain_core.callbacks.manager.CallbackManager.html"><span>CallbackManager</span></a></li><li><a href="https://api.python.langchain.com/en/latest/callbacks/langchain_core.callbacks.streaming_stdout.StreamingStdOutCallbackHandler.html"><span>StreamingStdOutCallbackHandler</span></a></li><li><a href="https://api.python.langchain.com/en/latest/prompts/langchain_core.prompts.prompt.PromptTemplate.html"><span>PromptTemplate</span></a></li></ul></div><p><strong>Consider using a template that suits your model! Check the models page on Hugging Face etc. to get a correct prompting template.</strong></p><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">template </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> </span><span class="token triple-quoted-string string" style="color:rgb(163, 21, 21)">&quot;&quot;&quot;Question: {question}</span><br></span><span class="token-line" style="color:#000000"><span class="token triple-quoted-string string" style="display:inline-block;color:rgb(163, 21, 21)"></span><br></span><span class="token-line" style="color:#000000"><span class="token triple-quoted-string string" style="color:rgb(163, 21, 21)">Answer: Let&#x27;s work this out in a step by step way to be sure we have the right answer.&quot;&quot;&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">prompt </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> PromptTemplate</span><span class="token punctuation" style="color:rgb(4, 81, 165)">.</span><span class="token plain">from_template</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token plain">template</span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token comment" style="color:rgb(0, 128, 0)"># Callbacks support token-wise streaming</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">callback_manager </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> CallbackManager</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token punctuation" style="color:rgb(4, 81, 165)">[</span><span class="token plain">StreamingStdOutCallbackHandler</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><span class="token punctuation" style="color:rgb(4, 81, 165)">]</span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h3 class="anchor anchorWithStickyNavbar_LWe7" id="cpu">CPU<a href="#cpu" class="hash-link" aria-label="Direct link to CPU" title="Direct link to CPU">​</a></h3><p>Example using a LLaMA 2 7B model</p><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token comment" style="color:rgb(0, 128, 0)"># Make sure the model path is correct for your system!</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">llm </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> LlamaCpp</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    model_path</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token string" style="color:rgb(163, 21, 21)">&quot;/Users/rlm/Desktop/Code/llama.cpp/models/openorca-platypus2-13b.gguf.q4_0.bin&quot;</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    temperature</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token number" style="color:rgb(9, 134, 88)">0.75</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    max_tokens</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token number" style="color:rgb(9, 134, 88)">2000</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    top_p</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token number" style="color:rgb(9, 134, 88)">1</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    callback_manager</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain">callback_manager</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    verbose</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token boolean">True</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain">  </span><span class="token comment" style="color:rgb(0, 128, 0)"># Verbose is required to pass to the callback manager</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain"></span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">question </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> </span><span class="token triple-quoted-string string" style="color:rgb(163, 21, 21)">&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#000000"><span class="token triple-quoted-string string" style="color:rgb(163, 21, 21)">Question: A rap battle between Stephen Colbert and John Oliver</span><br></span><span class="token-line" style="color:#000000"><span class="token triple-quoted-string string" style="color:rgb(163, 21, 21)">&quot;&quot;&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">llm</span><span class="token punctuation" style="color:rgb(4, 81, 165)">.</span><span class="token plain">invoke</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token plain">question</span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><div class="language-output codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-output codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">Stephen Colbert:</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">Yo, John, I heard you&#x27;ve been talkin&#x27; smack about me on your show.</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">Let me tell you somethin&#x27;, pal, I&#x27;m the king of late-night TV</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">My satire is sharp as a razor, it cuts deeper than a knife</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">While you&#x27;re just a british bloke tryin&#x27; to be funny with your accent and your wit.</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">John Oliver:</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">Oh Stephen, don&#x27;t be ridiculous, you may have the ratings but I got the real talk.</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">My show is the one that people actually watch and listen to, not just for the laughs but for the facts.</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">While you&#x27;re busy talkin&#x27; trash, I&#x27;m out here bringing the truth to light.</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">Stephen Colbert:</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">Truth? Ha! You think your show is about truth? Please, it&#x27;s all just a joke to you.</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">You&#x27;re just a fancy-pants british guy tryin&#x27; to be funny with your news and your jokes.</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">While I&#x27;m the one who&#x27;s really makin&#x27; a difference, with my sat</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">``````output</span><br></span><span class="token-line" style="color:#000000"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">llama_print_timings:        load time =   358.60 ms</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">llama_print_timings:      sample time =   172.55 ms /   256 runs   (    0.67 ms per token,  1483.59 tokens per second)</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">llama_print_timings: prompt eval time =   613.36 ms /    16 tokens (   38.33 ms per token,    26.09 tokens per second)</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">llama_print_timings:        eval time = 10151.17 ms /   255 runs   (   39.81 ms per token,    25.12 tokens per second)</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">llama_print_timings:       total time = 11332.41 ms</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><div class="language-output codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-output codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">&quot;\nStephen Colbert:\nYo, John, I heard you&#x27;ve been talkin&#x27; smack about me on your show.\nLet me tell you somethin&#x27;, pal, I&#x27;m the king of late-night TV\nMy satire is sharp as a razor, it cuts deeper than a knife\nWhile you&#x27;re just a british bloke tryin&#x27; to be funny with your accent and your wit.\nJohn Oliver:\nOh Stephen, don&#x27;t be ridiculous, you may have the ratings but I got the real talk.\nMy show is the one that people actually watch and listen to, not just for the laughs but for the facts.\nWhile you&#x27;re busy talkin&#x27; trash, I&#x27;m out here bringing the truth to light.\nStephen Colbert:\nTruth? Ha! You think your show is about truth? Please, it&#x27;s all just a joke to you.\nYou&#x27;re just a fancy-pants british guy tryin&#x27; to be funny with your news and your jokes.\nWhile I&#x27;m the one who&#x27;s really makin&#x27; a difference, with my sat&quot;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Example using a LLaMA v1 model</p><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token comment" style="color:rgb(0, 128, 0)"># Make sure the model path is correct for your system!</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">llm </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> LlamaCpp</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    model_path</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token string" style="color:rgb(163, 21, 21)">&quot;./ggml-model-q4_0.bin&quot;</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"> callback_manager</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain">callback_manager</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"> verbose</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token boolean">True</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain"></span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">llm_chain </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> prompt </span><span class="token operator" style="color:rgb(0, 0, 0)">|</span><span class="token plain"> llm</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">question </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(163, 21, 21)">&quot;What NFL team won the Super Bowl in the year Justin Bieber was born?&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">llm_chain</span><span class="token punctuation" style="color:rgb(4, 81, 165)">.</span><span class="token plain">invoke</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token punctuation" style="color:rgb(4, 81, 165)">{</span><span class="token string" style="color:rgb(163, 21, 21)">&quot;question&quot;</span><span class="token punctuation" style="color:rgb(4, 81, 165)">:</span><span class="token plain"> question</span><span class="token punctuation" style="color:rgb(4, 81, 165)">}</span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><div class="language-output codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-output codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">1. First, find out when Justin Bieber was born.</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">2. We know that Justin Bieber was born on March 1, 1994.</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">3. Next, we need to look up when the Super Bowl was played in that year.</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">4. The Super Bowl was played on January 28, 1995.</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">5. Finally, we can use this information to answer the question. The NFL team that won the Super Bowl in the year Justin Bieber was born is the San Francisco 49ers.</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">``````output</span><br></span><span class="token-line" style="color:#000000"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">llama_print_timings:        load time =   434.15 ms</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">llama_print_timings:      sample time =    41.81 ms /   121 runs   (    0.35 ms per token)</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">llama_print_timings: prompt eval time =  2523.78 ms /    48 tokens (   52.58 ms per token)</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">llama_print_timings:        eval time = 23971.57 ms /   121 runs   (  198.11 ms per token)</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">llama_print_timings:       total time = 28945.95 ms</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><div class="language-output codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-output codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">&#x27;\n\n1. First, find out when Justin Bieber was born.\n2. We know that Justin Bieber was born on March 1, 1994.\n3. Next, we need to look up when the Super Bowl was played in that year.\n4. The Super Bowl was played on January 28, 1995.\n5. Finally, we can use this information to answer the question. The NFL team that won the Super Bowl in the year Justin Bieber was born is the San Francisco 49ers.&#x27;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h3 class="anchor anchorWithStickyNavbar_LWe7" id="gpu">GPU<a href="#gpu" class="hash-link" aria-label="Direct link to GPU" title="Direct link to GPU">​</a></h3><p>If the installation with BLAS backend was correct, you will see a <code>BLAS = 1</code> indicator in model properties.</p><p>Two of the most important parameters for use with GPU are:</p><ul><li><code>n_gpu_layers</code> - determines how many layers of the model are offloaded to your GPU.</li><li><code>n_batch</code> - how many tokens are processed in parallel. </li></ul><p>Setting these parameters correctly will dramatically improve the evaluation speed (see <a href="https://github.com/langchain-ai/langchain/blob/master/libs/community/langchain_community/llms/llamacpp.py" target="_blank" rel="noopener noreferrer">wrapper code</a> for more details).</p><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">n_gpu_layers </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> </span><span class="token operator" style="color:rgb(0, 0, 0)">-</span><span class="token number" style="color:rgb(9, 134, 88)">1</span><span class="token plain">  </span><span class="token comment" style="color:rgb(0, 128, 0)"># The number of layers to put on the GPU. The rest will be on the CPU. If you don&#x27;t know how many layers there are, you can use -1 to move all to GPU.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">n_batch </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> </span><span class="token number" style="color:rgb(9, 134, 88)">512</span><span class="token plain">  </span><span class="token comment" style="color:rgb(0, 128, 0)"># Should be between 1 and n_ctx, consider the amount of VRAM in your GPU.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain"></span><span class="token comment" style="color:rgb(0, 128, 0)"># Make sure the model path is correct for your system!</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">llm </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> LlamaCpp</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    model_path</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token string" style="color:rgb(163, 21, 21)">&quot;/Users/rlm/Desktop/Code/llama.cpp/models/openorca-platypus2-13b.gguf.q4_0.bin&quot;</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    n_gpu_layers</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain">n_gpu_layers</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    n_batch</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain">n_batch</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    callback_manager</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain">callback_manager</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    verbose</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token boolean">True</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain">  </span><span class="token comment" style="color:rgb(0, 128, 0)"># Verbose is required to pass to the callback manager</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain"></span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">llm_chain </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> prompt </span><span class="token operator" style="color:rgb(0, 0, 0)">|</span><span class="token plain"> llm</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">question </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(163, 21, 21)">&quot;What NFL team won the Super Bowl in the year Justin Bieber was born?&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">llm_chain</span><span class="token punctuation" style="color:rgb(4, 81, 165)">.</span><span class="token plain">invoke</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token punctuation" style="color:rgb(4, 81, 165)">{</span><span class="token string" style="color:rgb(163, 21, 21)">&quot;question&quot;</span><span class="token punctuation" style="color:rgb(4, 81, 165)">:</span><span class="token plain"> question</span><span class="token punctuation" style="color:rgb(4, 81, 165)">}</span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><div class="language-output codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-output codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">1. Identify Justin Bieber&#x27;s birth date: Justin Bieber was born on March 1, 1994.</span><br></span><span class="token-line" style="color:#000000"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">2. Find the Super Bowl winner of that year: The NFL season of 1993 with the Super Bowl being played in January or of 1994.</span><br></span><span class="token-line" style="color:#000000"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">3. Determine which team won the game: The Dallas Cowboys faced the Buffalo Bills in Super Bowl XXVII on January 31, 1993 (as the year is mis-labelled due to a error). The Dallas Cowboys won this matchup.</span><br></span><span class="token-line" style="color:#000000"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">So, Justin Bieber was born when the Dallas Cowboys were the reigning NFL Super Bowl.</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">``````output</span><br></span><span class="token-line" style="color:#000000"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">llama_print_timings:        load time =   427.63 ms</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">llama_print_timings:      sample time =   115.85 ms /   164 runs   (    0.71 ms per token,  1415.67 tokens per second)</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">llama_print_timings: prompt eval time =   427.53 ms /    45 tokens (    9.50 ms per token,   105.26 tokens per second)</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">llama_print_timings:        eval time =  4526.53 ms /   163 runs   (   27.77 ms per token,    36.01 tokens per second)</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">llama_print_timings:       total time =  5293.77 ms</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><div class="language-output codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-output codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">&quot;\n\n1. Identify Justin Bieber&#x27;s birth date: Justin Bieber was born on March 1, 1994.\n\n2. Find the Super Bowl winner of that year: The NFL season of 1993 with the Super Bowl being played in January or of 1994.\n\n3. Determine which team won the game: The Dallas Cowboys faced the Buffalo Bills in Super Bowl XXVII on January 31, 1993 (as the year is mis-labelled due to a error). The Dallas Cowboys won this matchup.\n\nSo, Justin Bieber was born when the Dallas Cowboys were the reigning NFL Super Bowl.&quot;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h3 class="anchor anchorWithStickyNavbar_LWe7" id="metal">Metal<a href="#metal" class="hash-link" aria-label="Direct link to Metal" title="Direct link to Metal">​</a></h3><p>If the installation with Metal was correct, you will see a <code>NEON = 1</code> indicator in model properties.</p><p>Two of the most important GPU parameters are:</p><ul><li><code>n_gpu_layers</code> - determines how many layers of the model are offloaded to your Metal GPU.</li><li><code>n_batch</code> - how many tokens are processed in parallel, default is 8, set to bigger number.</li><li><code>f16_kv</code> - for some reason, Metal only support <code>True</code>, otherwise you will get error such as <code>Asserting on type 0
GGML_ASSERT: .../ggml-metal.m:706: false &amp;&amp; &quot;not implemented&quot;</code></li></ul><p>Setting these parameters correctly will dramatically improve the evaluation speed (see <a href="https://github.com/langchain-ai/langchain/blob/master/libs/community/langchain_community/llms/llamacpp.py" target="_blank" rel="noopener noreferrer">wrapper code</a> for more details).</p><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">n_gpu_layers </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> </span><span class="token number" style="color:rgb(9, 134, 88)">1</span><span class="token plain">  </span><span class="token comment" style="color:rgb(0, 128, 0)"># The number of layers to put on the GPU. The rest will be on the CPU. If you don&#x27;t know how many layers there are, you can use -1 to move all to GPU.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">n_batch </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> </span><span class="token number" style="color:rgb(9, 134, 88)">512</span><span class="token plain">  </span><span class="token comment" style="color:rgb(0, 128, 0)"># Should be between 1 and n_ctx, consider the amount of RAM of your Apple Silicon Chip.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain"></span><span class="token comment" style="color:rgb(0, 128, 0)"># Make sure the model path is correct for your system!</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">llm </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> LlamaCpp</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    model_path</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token string" style="color:rgb(163, 21, 21)">&quot;/Users/rlm/Desktop/Code/llama.cpp/models/openorca-platypus2-13b.gguf.q4_0.bin&quot;</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    n_gpu_layers</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain">n_gpu_layers</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    n_batch</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain">n_batch</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    f16_kv</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token boolean">True</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain">  </span><span class="token comment" style="color:rgb(0, 128, 0)"># MUST set to True, otherwise you will run into problem after a couple of calls</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    callback_manager</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain">callback_manager</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    verbose</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token boolean">True</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain">  </span><span class="token comment" style="color:rgb(0, 128, 0)"># Verbose is required to pass to the callback manager</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain"></span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>The console log will show the following log to indicate Metal was enable properly.</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">ggml_metal_init: allocating</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">ggml_metal_init: using MPS</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">...</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>You also could check <code>Activity Monitor</code> by watching the GPU usage of the process, the CPU usage will drop dramatically after turn on <code>n_gpu_layers=1</code>. </p><p>For the first call to the LLM, the performance may be slow due to the model compilation in Metal GPU.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="grammars">Grammars<a href="#grammars" class="hash-link" aria-label="Direct link to Grammars" title="Direct link to Grammars">​</a></h3><p>We can use <a href="https://github.com/ggerganov/llama.cpp/blob/master/grammars/README.md" target="_blank" rel="noopener noreferrer">grammars</a> to constrain model outputs and sample tokens based on the rules defined in them.</p><p>To demonstrate this concept, we&#x27;ve included <a href="https://github.com/langchain-ai/langchain/tree/master/libs/langchain/langchain/llms/grammars" target="_blank" rel="noopener noreferrer">sample grammar files</a>, that will be used in the examples below.</p><p>Creating gbnf grammar files can be time-consuming, but if you have a use-case where output schemas are important, there are two tools that can help:</p><ul><li><a href="https://grammar.intrinsiclabs.ai/" target="_blank" rel="noopener noreferrer">Online grammar generator app</a> that converts TypeScript interface definitions to gbnf file.</li><li><a href="https://github.com/ggerganov/llama.cpp/blob/master/examples/json-schema-to-grammar.py" target="_blank" rel="noopener noreferrer">Python script</a> for converting json schema to gbnf file. You can for example create <code>pydantic</code> object, generate its JSON schema using <code>.schema_json()</code> method, and then use this script to convert it to gbnf file.</li></ul><p>In the first example, supply the path to the specified <code>json.gbnf</code> file in order to produce JSON:</p><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">n_gpu_layers </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> </span><span class="token number" style="color:rgb(9, 134, 88)">1</span><span class="token plain">  </span><span class="token comment" style="color:rgb(0, 128, 0)"># The number of layers to put on the GPU. The rest will be on the CPU. If you don&#x27;t know how many layers there are, you can use -1 to move all to GPU.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">n_batch </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> </span><span class="token number" style="color:rgb(9, 134, 88)">512</span><span class="token plain">  </span><span class="token comment" style="color:rgb(0, 128, 0)"># Should be between 1 and n_ctx, consider the amount of RAM of your Apple Silicon Chip.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain"></span><span class="token comment" style="color:rgb(0, 128, 0)"># Make sure the model path is correct for your system!</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">llm </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> LlamaCpp</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    model_path</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token string" style="color:rgb(163, 21, 21)">&quot;/Users/rlm/Desktop/Code/llama.cpp/models/openorca-platypus2-13b.gguf.q4_0.bin&quot;</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    n_gpu_layers</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain">n_gpu_layers</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    n_batch</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain">n_batch</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    f16_kv</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token boolean">True</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain">  </span><span class="token comment" style="color:rgb(0, 128, 0)"># MUST set to True, otherwise you will run into problem after a couple of calls</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    callback_manager</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain">callback_manager</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    verbose</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token boolean">True</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain">  </span><span class="token comment" style="color:rgb(0, 128, 0)"># Verbose is required to pass to the callback manager</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    grammar_path</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token string" style="color:rgb(163, 21, 21)">&quot;/Users/rlm/Desktop/Code/langchain-main/langchain/libs/langchain/langchain/llms/grammars/json.gbnf&quot;</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain"></span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token operator" style="color:rgb(0, 0, 0)">%</span><span class="token operator" style="color:rgb(0, 0, 0)">%</span><span class="token plain">capture captured </span><span class="token operator" style="color:rgb(0, 0, 0)">-</span><span class="token operator" style="color:rgb(0, 0, 0)">-</span><span class="token plain">no</span><span class="token operator" style="color:rgb(0, 0, 0)">-</span><span class="token plain">stdout</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">result </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> llm</span><span class="token punctuation" style="color:rgb(4, 81, 165)">.</span><span class="token plain">invoke</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token string" style="color:rgb(163, 21, 21)">&quot;Describe a person in JSON format:&quot;</span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><div class="language-output codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-output codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">{</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">  &quot;name&quot;: &quot;John Doe&quot;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">  &quot;age&quot;: 34,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">  &quot;&quot;: {</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    &quot;title&quot;: &quot;Software Developer&quot;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    &quot;company&quot;: &quot;Google&quot;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">  },</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">  &quot;interests&quot;: [</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    &quot;Sports&quot;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    &quot;Music&quot;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    &quot;Cooking&quot;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">  ],</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">  &quot;address&quot;: {</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    &quot;street_number&quot;: 123,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    &quot;street_name&quot;: &quot;Oak Street&quot;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    &quot;city&quot;: &quot;Mountain View&quot;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    &quot;state&quot;: &quot;California&quot;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    &quot;postal_code&quot;: 94040</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">  }}</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">``````output</span><br></span><span class="token-line" style="color:#000000"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">llama_print_timings:        load time =   357.51 ms</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">llama_print_timings:      sample time =  1213.30 ms /   144 runs   (    8.43 ms per token,   118.68 tokens per second)</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">llama_print_timings: prompt eval time =   356.78 ms /     9 tokens (   39.64 ms per token,    25.23 tokens per second)</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">llama_print_timings:        eval time =  3947.16 ms /   143 runs   (   27.60 ms per token,    36.23 tokens per second)</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">llama_print_timings:       total time =  5846.21 ms</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>We can also supply <code>list.gbnf</code> to return a list:</p><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">n_gpu_layers </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> </span><span class="token number" style="color:rgb(9, 134, 88)">1</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">n_batch </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> </span><span class="token number" style="color:rgb(9, 134, 88)">512</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">llm </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> LlamaCpp</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    model_path</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token string" style="color:rgb(163, 21, 21)">&quot;/Users/rlm/Desktop/Code/llama.cpp/models/openorca-platypus2-13b.gguf.q4_0.bin&quot;</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    n_gpu_layers</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain">n_gpu_layers</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    n_batch</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain">n_batch</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    f16_kv</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token boolean">True</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain">  </span><span class="token comment" style="color:rgb(0, 128, 0)"># MUST set to True, otherwise you will run into problem after a couple of calls</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    callback_manager</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain">callback_manager</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    verbose</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token boolean">True</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    grammar_path</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token string" style="color:rgb(163, 21, 21)">&quot;/Users/rlm/Desktop/Code/langchain-main/langchain/libs/langchain/langchain/llms/grammars/list.gbnf&quot;</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain"></span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token operator" style="color:rgb(0, 0, 0)">%</span><span class="token operator" style="color:rgb(0, 0, 0)">%</span><span class="token plain">capture captured </span><span class="token operator" style="color:rgb(0, 0, 0)">-</span><span class="token operator" style="color:rgb(0, 0, 0)">-</span><span class="token plain">no</span><span class="token operator" style="color:rgb(0, 0, 0)">-</span><span class="token plain">stdout</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">result </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> llm</span><span class="token punctuation" style="color:rgb(4, 81, 165)">.</span><span class="token plain">invoke</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token string" style="color:rgb(163, 21, 21)">&quot;List of top-3 my favourite books:&quot;</span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><div class="language-output codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-output codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">[&quot;The Catcher in the Rye&quot;, &quot;Wuthering Heights&quot;, &quot;Anna Karenina&quot;]</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">``````output</span><br></span><span class="token-line" style="color:#000000"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">llama_print_timings:        load time =   322.34 ms</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">llama_print_timings:      sample time =   232.60 ms /    26 runs   (    8.95 ms per token,   111.78 tokens per second)</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">llama_print_timings: prompt eval time =   321.90 ms /    11 tokens (   29.26 ms per token,    34.17 tokens per second)</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">llama_print_timings:        eval time =   680.82 ms /    25 runs   (   27.23 ms per token,    36.72 tokens per second)</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">llama_print_timings:       total time =  1295.27 ms</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div><div style="display:flex;flex-direction:column"><hr><h4>Help us out by providing feedback on this documentation page:</h4><div style="display:flex;gap:5px"><div style="display:flex;align-items:center;padding-top:10px;padding-bottom:10px;padding-left:22px;padding-right:22px;border:1px solid gray;border-radius:6px;gap:10px;cursor:pointer;font-size:16px;font-weight:600" role="button" tabindex="0"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="#166534" style="width:24px;height:24px"><path stroke-linecap="round" stroke-linejoin="round" d="M6.633 10.25c.806 0 1.533-.446 2.031-1.08a9.041 9.041 0 0 1 2.861-2.4c.723-.384 1.35-.956 1.653-1.715a4.498 4.498 0 0 0 .322-1.672V2.75a.75.75 0 0 1 .75-.75 2.25 2.25 0 0 1 2.25 2.25c0 1.152-.26 2.243-.723 3.218-.266.558.107 1.282.725 1.282m0 0h3.126c1.026 0 1.945.694 2.054 1.715.045.422.068.85.068 1.285a11.95 11.95 0 0 1-2.649 7.521c-.388.482-.987.729-1.605.729H13.48c-.483 0-.964-.078-1.423-.23l-3.114-1.04a4.501 4.501 0 0 0-1.423-.23H5.904m10.598-9.75H14.25M5.904 18.5c.083.205.173.405.27.602.197.4-.078.898-.523.898h-.908c-.889 0-1.713-.518-1.972-1.368a12 12 0 0 1-.521-3.507c0-1.553.295-3.036.831-4.398C3.387 9.953 4.167 9.5 5 9.5h1.053c.472 0 .745.556.5.96a8.958 8.958 0 0 0-1.302 4.665c0 1.194.232 2.333.654 3.375Z"></path></svg></div><div style="display:flex;align-items:center;padding-top:10px;padding-bottom:10px;padding-left:22px;padding-right:22px;border:1px solid gray;border-radius:6px;gap:10px;cursor:pointer;font-size:16px;font-weight:600" role="button" tabindex="0"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="#991b1b" style="width:24px;height:24px"><path stroke-linecap="round" stroke-linejoin="round" d="M7.498 15.25H4.372c-1.026 0-1.945-.694-2.054-1.715a12.137 12.137 0 0 1-.068-1.285c0-2.848.992-5.464 2.649-7.521C5.287 4.247 5.886 4 6.504 4h4.016a4.5 4.5 0 0 1 1.423.23l3.114 1.04a4.5 4.5 0 0 0 1.423.23h1.294M7.498 15.25c.618 0 .991.724.725 1.282A7.471 7.471 0 0 0 7.5 19.75 2.25 2.25 0 0 0 9.75 22a.75.75 0 0 0 .75-.75v-.633c0-.573.11-1.14.322-1.672.304-.76.93-1.33 1.653-1.715a9.04 9.04 0 0 0 2.86-2.4c.498-.634 1.226-1.08 2.032-1.08h.384m-10.253 1.5H9.7m8.075-9.75c.01.05.027.1.05.148.593 1.2.925 2.55.925 3.977 0 1.487-.36 2.89-.999 4.125m.023-8.25c-.076-.365.183-.75.575-.75h.908c.889 0 1.713.518 1.972 1.368.339 1.11.521 2.287.521 3.507 0 1.553-.295 3.036-.831 4.398-.306.774-1.086 1.227-1.918 1.227h-1.053c-.472 0-.745-.556-.5-.96a8.95 8.95 0 0 0 .303-.54"></path></svg></div></div></div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/v0.1/docs/integrations/llms/layerup_security/"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Layerup Security</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/v0.1/docs/integrations/llms/llamafile/"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Llamafile</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#installation" class="table-of-contents__link toc-highlight">Installation</a><ul><li><a href="#cpu-only-installation" class="table-of-contents__link toc-highlight">CPU only installation</a></li><li><a href="#installation-with-openblas--cublas--clblast" class="table-of-contents__link toc-highlight">Installation with OpenBLAS / cuBLAS / CLBlast</a></li><li><a href="#installation-with-metal" class="table-of-contents__link toc-highlight">Installation with Metal</a></li><li><a href="#installation-with-windows" class="table-of-contents__link toc-highlight">Installation with Windows</a></li></ul></li><li><a href="#usage" class="table-of-contents__link toc-highlight">Usage</a><ul><li><a href="#cpu" class="table-of-contents__link toc-highlight">CPU</a></li><li><a href="#gpu" class="table-of-contents__link toc-highlight">GPU</a></li><li><a href="#metal" class="table-of-contents__link toc-highlight">Metal</a></li><li><a href="#grammars" class="table-of-contents__link toc-highlight">Grammars</a></li></ul></li></ul></div></div></div></div></main></div></div><footer class="footer"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://discord.gg/cU2adEyC7w" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://twitter.com/LangChainAI" target="_blank" rel="noopener noreferrer" class="footer__link-item">Twitter<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">GitHub</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/langchain-ai/langchain" target="_blank" rel="noopener noreferrer" class="footer__link-item">Python<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://github.com/langchain-ai/langchainjs" target="_blank" rel="noopener noreferrer" class="footer__link-item">JS/TS<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://langchain.com" target="_blank" rel="noopener noreferrer" class="footer__link-item">Homepage<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://blog.langchain.dev" target="_blank" rel="noopener noreferrer" class="footer__link-item">Blog<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.youtube.com/@LangChain" target="_blank" rel="noopener noreferrer" class="footer__link-item">YouTube<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2024 LangChain, Inc.</div></div></div></footer></div>
<script src="/v0.1/assets/js/runtime~main.1cd6ff7f.js"></script>
<script src="/v0.1/assets/js/main.524fe94c.js"></script>
</body>
</html>