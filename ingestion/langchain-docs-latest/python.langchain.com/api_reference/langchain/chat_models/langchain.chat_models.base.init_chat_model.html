
<!DOCTYPE html>

<html data-content_root="../../" lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/><meta content="width=device-width, initial-scale=1" name="viewport"/>
<!-- Google tag (gtag.js) -->
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-9B66JQQH2F"></script>
<script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'G-9B66JQQH2F');
    </script>
<title>init_chat_model ‚Äî ü¶úüîó LangChain  documentation</title>
<script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
<!--
    this give us a css class that will be invisible only if js is disabled
  -->
<noscript>
<style>
      .pst-js-only { display: none !important; }

    </style>
</noscript>
<!-- Loaded before other Sphinx assets -->
<link href="../../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet"/>
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet"/>
<link href="../../_static/pygments.css?v=8f2a1f02" rel="stylesheet" type="text/css"/>
<link href="../../_static/autodoc_pydantic.css" rel="stylesheet" type="text/css"/>
<link href="../../_static/copybutton.css?v=76b2166b" rel="stylesheet" type="text/css"/>
<link href="../../_static/sphinx-design.min.css?v=95c83b7e" rel="stylesheet" type="text/css"/>
<link href="../../_static/css/custom.css?v=8e9fa5b3" rel="stylesheet" type="text/css"/>
<!-- So that users can add custom icons -->
<script src="../../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
<!-- Pre-loaded scripts that we'll load fully later -->
<link as="script" href="../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" rel="preload"/>
<link as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" rel="preload"/>
<script src="../../_static/documentation_options.js?v=3b5cce75"></script>
<script src="../../_static/doctools.js?v=9bcbadda"></script>
<script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
<script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
<script src="../../_static/copybutton.js?v=f281be69"></script>
<script src="../../_static/design-tabs.js?v=f930bc37"></script>
<script>DOCUMENTATION_OPTIONS.pagename = 'langchain/chat_models/langchain.chat_models.base.init_chat_model';</script>
<link href="../../_static/favicon.png" rel="icon"/>
<link href="../../search.html" rel="search" title="Search"/>
<link href="../embeddings.html" rel="next" title="embeddings"/>
<link href="../chat_models.html" rel="prev" title="chat_models"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="en" name="docsearch:language"/>
<meta content="" name="docsearch:version"/>
<meta content="Jul 10, 2025" name="docbuild:last-update"/>
</head>
<body data-bs-root-margin="0px 0px -60%" data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-default-mode="" data-offset="180">
<div class="skip-link d-print-none" id="pst-skip-link"><a href="#main-content">Skip to main content</a></div>
<div id="pst-scroll-pixel-helper"></div>
<button class="btn rounded-pill" id="pst-back-to-top" type="button">
<i class="fa-solid fa-arrow-up"></i>Back to top</button>
<dialog id="pst-search-dialog">
<form action="../../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="fa-solid fa-magnifying-glass"></i>
<input aria-label="Search" autocapitalize="off" autocomplete="off" autocorrect="off" class="form-control" name="q" placeholder="Search" spellcheck="false" type="search"/>
<span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</dialog>
<div class="pst-async-banner-revealer d-none">
<aside aria-label="Version warning" class="d-none d-print-none" id="bd-header-version-warning"></aside>
</div>
<header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
<button aria-label="Site navigation" class="pst-navbar-icon sidebar-toggle primary-toggle">
<span class="fa-solid fa-bars"></span>
</button>
<div class="navbar-header-items__start">
<div class="navbar-item">
<a class="navbar-brand logo" href="../../index.html">
<img alt="ü¶úüîó LangChain  documentation - Home" class="logo__image only-light" src="../../_static/wordmark-api.svg"/>
<img alt="ü¶úüîó LangChain  documentation - Home" class="logo__image only-dark pst-js-only" src="../../_static/wordmark-api-dark.svg"/>
</a></div>
</div>
<div class="navbar-header-items">
<div class="me-auto navbar-header-items__center">
<div class="navbar-item">
<nav>
<ul class="bd-navbar-elements navbar-nav">
<li class="nav-item current active">
<a class="nav-link nav-internal" href="../../reference.html">
    Reference
  </a>
</li>
</ul>
</nav></div>
</div>
<div class="navbar-header-items__end">
<div class="navbar-item navbar-persistent--container">
<form action="../../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="fa-solid fa-magnifying-glass"></i>
<input aria-label="Search" autocapitalize="off" autocomplete="off" autocorrect="off" class="form-control" name="q" placeholder="Search" spellcheck="false" type="search"/>
<span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
<div class="navbar-item"><!-- This will display a link to LangChain docs -->
<head>
<style>
        .text-link {
            text-decoration: none; /* Remove underline */
            color: inherit;        /* Inherit color from parent element */
        }
    </style>
</head>
<body>
<a class="text-link" href="https://python.langchain.com/">Docs</a>
</body></div>
<div class="navbar-item">
<button aria-label="Color mode" class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" data-bs-placement="bottom" data-bs-title="Color mode" data-bs-toggle="tooltip">
<i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light" title="Light"></i>
<i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark" title="Dark"></i>
<i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto" title="System Settings"></i>
</button></div>
<div class="navbar-item"><ul aria-label="Quick Links" class="navbar-icon-links">
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://github.com/langchain-ai/langchain" rel="noopener" target="_blank" title="GitHub"><i aria-hidden="true" class="fa-brands fa-square-github fa-lg"></i>
<span class="sr-only">GitHub</span></a>
</li>
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://twitter.com/langchainai" rel="noopener" target="_blank" title="X / Twitter"><i aria-hidden="true" class="fab fa-twitter-square fa-lg"></i>
<span class="sr-only">X / Twitter</span></a>
</li>
</ul></div>
</div>
</div>
<div class="navbar-persistent--mobile">
<form action="../../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="fa-solid fa-magnifying-glass"></i>
<input aria-label="Search" autocapitalize="off" autocomplete="off" autocorrect="off" class="form-control" name="q" placeholder="Search" spellcheck="false" type="search"/>
<span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
<button aria-label="On this page" class="pst-navbar-icon sidebar-toggle secondary-toggle">
<span class="fa-solid fa-outdent"></span>
</button>
</div>
</header>
<div class="bd-container">
<div class="bd-container__inner bd-page-width">
<dialog id="pst-primary-sidebar-modal"></dialog>
<div class="bd-sidebar-primary bd-sidebar" id="pst-primary-sidebar">
<div class="sidebar-header-items sidebar-primary__section">
<div class="sidebar-header-items__center">
<div class="navbar-item">
<nav>
<ul class="bd-navbar-elements navbar-nav">
<li class="nav-item current active">
<a class="nav-link nav-internal" href="../../reference.html">
    Reference
  </a>
</li>
</ul>
</nav></div>
</div>
<div class="sidebar-header-items__end">
<div class="navbar-item"><!-- This will display a link to LangChain docs -->
<head>
<style>
        .text-link {
            text-decoration: none; /* Remove underline */
            color: inherit;        /* Inherit color from parent element */
        }
    </style>
</head>
<body>
<a class="text-link" href="https://python.langchain.com/">Docs</a>
</body></div>
<div class="navbar-item">
<button aria-label="Color mode" class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" data-bs-placement="bottom" data-bs-title="Color mode" data-bs-toggle="tooltip">
<i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light" title="Light"></i>
<i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark" title="Dark"></i>
<i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto" title="System Settings"></i>
</button></div>
<div class="navbar-item"><ul aria-label="Quick Links" class="navbar-icon-links">
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://github.com/langchain-ai/langchain" rel="noopener" target="_blank" title="GitHub"><i aria-hidden="true" class="fa-brands fa-square-github fa-lg"></i>
<span class="sr-only">GitHub</span></a>
</li>
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://twitter.com/langchainai" rel="noopener" target="_blank" title="X / Twitter"><i aria-hidden="true" class="fab fa-twitter-square fa-lg"></i>
<span class="sr-only">X / Twitter</span></a>
</li>
</ul></div>
</div>
</div>
<div class="sidebar-primary-items__start sidebar-primary__section">
<div class="sidebar-primary-item">
<nav aria-label="Section Navigation" class="bd-docs-nav bd-links">
<p aria-level="1" class="bd-links__title" role="heading">Section Navigation</p>
<div class="bd-toc-item navbar-nav"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Base packages</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../core/index.html">Core</a></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../index.html">Langchain</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../agents.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">agents</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../callbacks.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">callbacks</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../chains.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">chains</span></code></a></li>
<li class="toctree-l2 current active has-children"><a class="reference internal" href="../chat_models.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">chat_models</span></code></a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l3 current active"><a class="current reference internal" href="#">init_chat_model</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../embeddings.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">embeddings</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../evaluation.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">evaluation</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../globals.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">globals</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../hub.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">hub</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../indexes.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">indexes</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../memory.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">memory</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../model_laboratory.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">model_laboratory</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../output_parsers.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">output_parsers</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../retrievers.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">retrievers</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../runnables.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">runnables</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../smith.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">smith</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../storage.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">storage</span></code></a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../../text_splitters/index.html">Text Splitters</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../community/index.html">Community</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../experimental/index.html">Experimental</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Integrations</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../ai21/index.html">AI21</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../anthropic/index.html">Anthropic</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../astradb/index.html">AstraDB</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../aws/index.html">AWS</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../azure_ai/index.html">Azure Ai</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../azure_dynamic_sessions/index.html">Azure Dynamic Sessions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../cerebras/index.html">Cerebras</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../chroma/index.html">Chroma</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../cohere/index.html">Cohere</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../db2/index.html">Db2</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deepseek/index.html">Deepseek</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../elasticsearch/index.html">Elasticsearch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../exa/index.html">Exa</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../fireworks/index.html">Fireworks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../google_community/index.html">Google Community</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../google_genai/index.html">Google GenAI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../google_vertexai/index.html">Google VertexAI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../groq/index.html">Groq</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../huggingface/index.html">Huggingface</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ibm/index.html">IBM</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../milvus/index.html">Milvus</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mistralai/index.html">MistralAI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mongodb/index.html">MongoDB</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../neo4j/index.html">Neo4J</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../nomic/index.html">Nomic</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../nvidia_ai_endpoints/index.html">Nvidia Ai Endpoints</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ollama/index.html">Ollama</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../openai/index.html">OpenAI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../perplexity/index.html">Perplexity</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../pinecone/index.html">Pinecone</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../postgres/index.html">Postgres</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../prompty/index.html">Prompty</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../qdrant/index.html">Qdrant</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../redis/index.html">Redis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../sema4/index.html">Sema4</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../snowflake/index.html">Snowflake</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../sqlserver/index.html">Sqlserver</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../standard_tests/index.html">Standard Tests</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tavily/index.html">Tavily</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../together/index.html">Together</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../unstructured/index.html">Unstructured</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../upstage/index.html">Upstage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../weaviate/index.html">Weaviate</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../xai/index.html">XAI</a></li>
</ul>
</div>
</nav></div>
</div>
<div class="sidebar-primary-items__end sidebar-primary__section">
<div class="sidebar-primary-item">
<div class="flat" data-ea-manual="true" data-ea-publisher="readthedocs" data-ea-type="readthedocs-sidebar" id="ethical-ad-placement">
</div></div>
</div>
</div>
<main class="bd-main" id="main-content" role="main">
<div class="bd-content">
<div class="bd-article-container">
<div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
<div class="header-article-items__start">
<div class="header-article-item">
<nav aria-label="Breadcrumb" class="d-print-none">
<ul class="bd-breadcrumbs">
<li class="breadcrumb-item breadcrumb-home">
<a aria-label="Home" class="nav-link" href="../../index.html">
<i class="fa-solid fa-home"></i>
</a>
</li>
<li class="breadcrumb-item"><a class="nav-link" href="../../reference.html">LangChain Python API Reference</a></li>
<li class="breadcrumb-item"><a class="nav-link" href="../index.html">langchain: 0.3.26</a></li>
<li class="breadcrumb-item"><a class="nav-link" href="../chat_models.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">chat_models</span></code></a></li>
<li aria-current="page" class="breadcrumb-item active"><span class="ellipsis">init_chat_model</span></li>
</ul>
</nav>
</div>
</div>
</div>
</div>
<div id="searchbox"></div>
<article class="bd-article">
<section id="init-chat-model">
<h1>init_chat_model<a class="headerlink" href="#init-chat-model" title="Link to this heading">#</a></h1>
<dl class="py function">
<dt class="sig sig-object py" id="langchain.chat_models.base.init_chat_model">
<span class="sig-prename descclassname"><span class="pre">langchain.chat_models.base.</span></span><span class="sig-name descname"><span class="pre">init_chat_model</span></span><span class="sig-paren">(</span>
<dl>
<dd><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>,</dd>
<dd><em class="sig-param"><span class="keyword-only-separator o"><abbr title="Keyword-only parameters separator (PEP 3102)"><span class="pre">*</span></abbr></span></em>,</dd>
<dd><em class="sig-param"><span class="n"><span class="pre">model_provider</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>,</dd>
<dd><em class="sig-param"><span class="n"><span class="pre">configurable_fields</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="pre">None</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>,</dd>
<dd><em class="sig-param"><span class="n"><span class="pre">config_prefix</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>,</dd>
<dd><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em>,</dd>
</dl>
<span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">‚Üí</span> <span class="sig-return-typehint"><a class="reference internal" href="../../core/language_models/langchain_core.language_models.chat_models.BaseChatModel.html#langchain_core.language_models.chat_models.BaseChatModel" title="langchain_core.language_models.chat_models.BaseChatModel"><span class="pre">BaseChatModel</span></a></span></span><a class="reference internal" href="../../_modules/langchain/chat_models/base.html#init_chat_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.chat_models.base.init_chat_model" title="Link to this definition">#</a></dt>
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">langchain.chat_models.base.</span></span><span class="sig-name descname"><span class="pre">init_chat_model</span></span><span class="sig-paren">(</span>
<dl>
<dd><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="pre">None</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>,</dd>
<dd><em class="sig-param"><span class="keyword-only-separator o"><abbr title="Keyword-only parameters separator (PEP 3102)"><span class="pre">*</span></abbr></span></em>,</dd>
<dd><em class="sig-param"><span class="n"><span class="pre">model_provider</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>,</dd>
<dd><em class="sig-param"><span class="n"><span class="pre">configurable_fields</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="pre">None</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>,</dd>
<dd><em class="sig-param"><span class="n"><span class="pre">config_prefix</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>,</dd>
<dd><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em>,</dd>
</dl>
<span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">‚Üí</span> <span class="sig-return-typehint"><span class="pre">_ConfigurableModel</span></span></span></dt>
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">langchain.chat_models.base.</span></span><span class="sig-name descname"><span class="pre">init_chat_model</span></span><span class="sig-paren">(</span>
<dl>
<dd><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>,</dd>
<dd><em class="sig-param"><span class="keyword-only-separator o"><abbr title="Keyword-only parameters separator (PEP 3102)"><span class="pre">*</span></abbr></span></em>,</dd>
<dd><em class="sig-param"><span class="n"><span class="pre">model_provider</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>,</dd>
<dd><em class="sig-param"><span class="n"><span class="pre">configurable_fields</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'any'</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>,</dd>
<dd><em class="sig-param"><span class="n"><span class="pre">config_prefix</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>,</dd>
<dd><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em>,</dd>
</dl>
<span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">‚Üí</span> <span class="sig-return-typehint"><span class="pre">_ConfigurableModel</span></span></span></dt>
<dd><p>Initialize a ChatModel from the model name and provider.</p>
<p><strong>Note:</strong> Must have the integration package corresponding to the model provider
installed.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> ‚Äì The name of the model, e.g. ‚Äúo3-mini‚Äù, ‚Äúclaude-3-5-sonnet-latest‚Äù. You can
also specify model and model provider in a single argument using
‚Äò{model_provider}:{model}‚Äô format, e.g. ‚Äúopenai:o1‚Äù.</p></li>
<li><p><strong>model_provider</strong> ‚Äì <p>The model provider if not specified as part of model arg (see
above). Supported model_provider values and the corresponding integration
package are:</p>
<ul>
<li><p>‚Äôopenai‚Äô              -&gt; langchain-openai</p></li>
<li><p>‚Äôanthropic‚Äô           -&gt; langchain-anthropic</p></li>
<li><p>‚Äôazure_openai‚Äô        -&gt; langchain-openai</p></li>
<li><p>‚Äôazure_ai‚Äô            -&gt; langchain-azure-ai</p></li>
<li><p>‚Äôgoogle_vertexai‚Äô     -&gt; langchain-google-vertexai</p></li>
<li><p>‚Äôgoogle_genai‚Äô        -&gt; langchain-google-genai</p></li>
<li><p>‚Äôbedrock‚Äô             -&gt; langchain-aws</p></li>
<li><p>‚Äôbedrock_converse‚Äô    -&gt; langchain-aws</p></li>
<li><p>‚Äôcohere‚Äô              -&gt; langchain-cohere</p></li>
<li><p>‚Äôfireworks‚Äô           -&gt; langchain-fireworks</p></li>
<li><p>‚Äôtogether‚Äô            -&gt; langchain-together</p></li>
<li><p>‚Äômistralai‚Äô           -&gt; langchain-mistralai</p></li>
<li><p>‚Äôhuggingface‚Äô         -&gt; langchain-huggingface</p></li>
<li><p>‚Äôgroq‚Äô                -&gt; langchain-groq</p></li>
<li><p>‚Äôollama‚Äô              -&gt; langchain-ollama</p></li>
<li><p>‚Äôgoogle_anthropic_vertex‚Äô    -&gt; langchain-google-vertexai</p></li>
<li><p>‚Äôdeepseek‚Äô            -&gt; langchain-deepseek</p></li>
<li><p>‚Äôibm‚Äô                 -&gt; langchain-ibm</p></li>
<li><p>‚Äônvidia‚Äô              -&gt; langchain-nvidia-ai-endpoints</p></li>
<li><p>‚Äôxai‚Äô                 -&gt; langchain-xai</p></li>
<li><p>‚Äôperplexity‚Äô          -&gt; langchain-perplexity</p></li>
</ul>
<p>Will attempt to infer model_provider from model if not specified. The
following providers will be inferred based on these model prefixes:</p>
<ul>
<li><p>‚Äôgpt-3‚Ä¶‚Äô | ‚Äògpt-4‚Ä¶‚Äô | ‚Äòo1‚Ä¶‚Äô -&gt; ‚Äòopenai‚Äô</p></li>
<li><p>‚Äôclaude‚Ä¶‚Äô                       -&gt; ‚Äòanthropic‚Äô</p></li>
<li><p>‚Äôamazon‚Ä¶.‚Äô                      -&gt; ‚Äòbedrock‚Äô</p></li>
<li><p>‚Äôgemini‚Ä¶‚Äô                       -&gt; ‚Äògoogle_vertexai‚Äô</p></li>
<li><p>‚Äôcommand‚Ä¶‚Äô                      -&gt; ‚Äòcohere‚Äô</p></li>
<li><p>‚Äôaccounts/fireworks‚Ä¶‚Äô           -&gt; ‚Äòfireworks‚Äô</p></li>
<li><p>‚Äômistral‚Ä¶‚Äô                      -&gt; ‚Äòmistralai‚Äô</p></li>
<li><p>‚Äôdeepseek‚Ä¶‚Äô                     -&gt; ‚Äòdeepseek‚Äô</p></li>
<li><p>‚Äôgrok‚Ä¶‚Äô                         -&gt; ‚Äòxai‚Äô</p></li>
<li><p>‚Äôsonar‚Ä¶‚Äô                        -&gt; ‚Äòperplexity‚Äô</p></li>
</ul>
</p></li>
<li><p><strong>configurable_fields</strong> ‚Äì <p>Which model parameters are
configurable:</p>
<ul>
<li><p>None: No configurable fields.</p></li>
<li><p>‚Äùany‚Äù: All fields are configurable. <em>See Security Note below.</em></p></li>
<li><p>Union[List[str], Tuple[str, ‚Ä¶]]: Specified fields are configurable.</p></li>
</ul>
<p>Fields are assumed to have config_prefix stripped if there is a
config_prefix. If model is specified, then defaults to None. If model is
not specified, then defaults to <code class="docutils literal notranslate"><span class="pre">("model",</span> <span class="pre">"model_provider")</span></code>.</p>
<p><strong>*Security Note*</strong>: Setting <code class="docutils literal notranslate"><span class="pre">configurable_fields="any"</span></code> means fields like
api_key, base_url, etc. can be altered at runtime, potentially redirecting
model requests to a different service/user. Make sure that if you‚Äôre
accepting untrusted configurations that you enumerate the
<code class="docutils literal notranslate"><span class="pre">configurable_fields=(...)</span></code> explicitly.</p>
</p></li>
<li><p><strong>config_prefix</strong> ‚Äì If config_prefix is a non-empty string then model will be
configurable at runtime via the
<code class="docutils literal notranslate"><span class="pre">config["configurable"]["{config_prefix}_{param}"]</span></code> keys. If
config_prefix is an empty string then model will be configurable via
<code class="docutils literal notranslate"><span class="pre">config["configurable"]["{param}"]</span></code>.</p></li>
<li><p><strong>temperature</strong> ‚Äì Model temperature.</p></li>
<li><p><strong>max_tokens</strong> ‚Äì Max output tokens.</p></li>
<li><p><strong>timeout</strong> ‚Äì The maximum time (in seconds) to wait for a response from the model
before canceling the request.</p></li>
<li><p><strong>max_retries</strong> ‚Äì The maximum number of attempts the system will make to resend a
request if it fails due to issues like network timeouts or rate limits.</p></li>
<li><p><strong>base_url</strong> ‚Äì The URL of the API endpoint where requests are sent.</p></li>
<li><p><strong>rate_limiter</strong> ‚Äì A <code class="docutils literal notranslate"><span class="pre">BaseRateLimiter</span></code> to space out requests to avoid exceeding
rate limits.</p></li>
<li><p><strong>kwargs</strong> ‚Äì Additional model-specific keyword args to pass to
<code class="docutils literal notranslate"><span class="pre">&lt;&lt;selected</span> <span class="pre">ChatModel&gt;&gt;.__init__(model=model_name,</span> <span class="pre">**kwargs)</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A BaseChatModel corresponding to the model_name and model_provider specified if
configurability is inferred to be False. If configurable, a chat model emulator
that initializes the underlying model at runtime once a config is passed in.</p>
</dd>
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ValueError</strong> ‚Äì If model_provider cannot be inferred or isn‚Äôt supported.</p></li>
<li><p><strong>ImportError</strong> ‚Äì If the model provider integration package is not installed.</p></li>
</ul>
</dd>
</dl>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" open="open">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Init non-configurable model</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg aria-hidden="true" class="sd-octicon sd-octicon-chevron-right" height="1.5em" version="1.1" viewbox="0 0 24 24" width="1.5em"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># pip install langchain langchain-openai langchain-anthropic langchain-google-vertexai</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain.chat_models</span><span class="w"> </span><span class="kn">import</span> <span class="n">init_chat_model</span>

<span class="n">o3_mini</span> <span class="o">=</span> <span class="n">init_chat_model</span><span class="p">(</span><span class="s2">"openai:o3-mini"</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">claude_sonnet</span> <span class="o">=</span> <span class="n">init_chat_model</span><span class="p">(</span><span class="s2">"anthropic:claude-3-5-sonnet-latest"</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">gemini_2_flash</span> <span class="o">=</span> <span class="n">init_chat_model</span><span class="p">(</span><span class="s2">"google_vertexai:gemini-2.0-flash"</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">o3_mini</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="s2">"what's your name"</span><span class="p">)</span>
<span class="n">claude_sonnet</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="s2">"what's your name"</span><span class="p">)</span>
<span class="n">gemini_2_flash</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="s2">"what's your name"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details><details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Partially configurable model with no default</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg aria-hidden="true" class="sd-octicon sd-octicon-chevron-right" height="1.5em" version="1.1" viewbox="0 0 24 24" width="1.5em"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># pip install langchain langchain-openai langchain-anthropic</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain.chat_models</span><span class="w"> </span><span class="kn">import</span> <span class="n">init_chat_model</span>

<span class="c1"># We don't need to specify configurable=True if a model isn't specified.</span>
<span class="n">configurable_model</span> <span class="o">=</span> <span class="n">init_chat_model</span><span class="p">(</span><span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">configurable_model</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span>
    <span class="s2">"what's your name"</span><span class="p">,</span>
    <span class="n">config</span><span class="o">=</span><span class="p">{</span><span class="s2">"configurable"</span><span class="p">:</span> <span class="p">{</span><span class="s2">"model"</span><span class="p">:</span> <span class="s2">"gpt-4o"</span><span class="p">}}</span>
<span class="p">)</span>
<span class="c1"># GPT-4o response</span>

<span class="n">configurable_model</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span>
    <span class="s2">"what's your name"</span><span class="p">,</span>
    <span class="n">config</span><span class="o">=</span><span class="p">{</span><span class="s2">"configurable"</span><span class="p">:</span> <span class="p">{</span><span class="s2">"model"</span><span class="p">:</span> <span class="s2">"claude-3-5-sonnet-latest"</span><span class="p">}}</span>
<span class="p">)</span>
<span class="c1"># claude-3.5 sonnet response</span>
</pre></div>
</div>
</div>
</details><details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Fully configurable model with a default</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg aria-hidden="true" class="sd-octicon sd-octicon-chevron-right" height="1.5em" version="1.1" viewbox="0 0 24 24" width="1.5em"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># pip install langchain langchain-openai langchain-anthropic</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain.chat_models</span><span class="w"> </span><span class="kn">import</span> <span class="n">init_chat_model</span>

<span class="n">configurable_model_with_default</span> <span class="o">=</span> <span class="n">init_chat_model</span><span class="p">(</span>
    <span class="s2">"openai:gpt-4o"</span><span class="p">,</span>
    <span class="n">configurable_fields</span><span class="o">=</span><span class="s2">"any"</span><span class="p">,</span>  <span class="c1"># this allows us to configure other params like temperature, max_tokens, etc at runtime.</span>
    <span class="n">config_prefix</span><span class="o">=</span><span class="s2">"foo"</span><span class="p">,</span>
    <span class="n">temperature</span><span class="o">=</span><span class="mi">0</span>
<span class="p">)</span>

<span class="n">configurable_model_with_default</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="s2">"what's your name"</span><span class="p">)</span>
<span class="c1"># GPT-4o response with temperature 0</span>

<span class="n">configurable_model_with_default</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span>
    <span class="s2">"what's your name"</span><span class="p">,</span>
    <span class="n">config</span><span class="o">=</span><span class="p">{</span>
        <span class="s2">"configurable"</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">"foo_model"</span><span class="p">:</span> <span class="s2">"anthropic:claude-3-5-sonnet-20240620"</span><span class="p">,</span>
            <span class="s2">"foo_temperature"</span><span class="p">:</span> <span class="mf">0.6</span>
        <span class="p">}</span>
    <span class="p">}</span>
<span class="p">)</span>
<span class="c1"># Claude-3.5 sonnet response with temperature 0.6</span>
</pre></div>
</div>
</div>
</details><details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Bind tools to a configurable model</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg aria-hidden="true" class="sd-octicon sd-octicon-chevron-right" height="1.5em" version="1.1" viewbox="0 0 24 24" width="1.5em"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">You can call any ChatModel declarative methods on a configurable model in the
same way that you would with a normal model.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># pip install langchain langchain-openai langchain-anthropic</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain.chat_models</span><span class="w"> </span><span class="kn">import</span> <span class="n">init_chat_model</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pydantic</span><span class="w"> </span><span class="kn">import</span> <span class="n">BaseModel</span><span class="p">,</span> <span class="n">Field</span>

<span class="k">class</span><span class="w"> </span><span class="nc">GetWeather</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
<span class="w">    </span><span class="sd">'''Get the current weather in a given location'''</span>

    <span class="n">location</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">Field</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s2">"The city and state, e.g. San Francisco, CA"</span><span class="p">)</span>

<span class="k">class</span><span class="w"> </span><span class="nc">GetPopulation</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
<span class="w">    </span><span class="sd">'''Get the current population in a given location'''</span>

    <span class="n">location</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">Field</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s2">"The city and state, e.g. San Francisco, CA"</span><span class="p">)</span>

<span class="n">configurable_model</span> <span class="o">=</span> <span class="n">init_chat_model</span><span class="p">(</span>
    <span class="s2">"gpt-4o"</span><span class="p">,</span>
    <span class="n">configurable_fields</span><span class="o">=</span><span class="p">(</span><span class="s2">"model"</span><span class="p">,</span> <span class="s2">"model_provider"</span><span class="p">),</span>
    <span class="n">temperature</span><span class="o">=</span><span class="mi">0</span>
<span class="p">)</span>

<span class="n">configurable_model_with_tools</span> <span class="o">=</span> <span class="n">configurable_model</span><span class="o">.</span><span class="n">bind_tools</span><span class="p">([</span><span class="n">GetWeather</span><span class="p">,</span> <span class="n">GetPopulation</span><span class="p">])</span>
<span class="n">configurable_model_with_tools</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span>
    <span class="s2">"Which city is hotter today and which is bigger: LA or NY?"</span>
<span class="p">)</span>
<span class="c1"># GPT-4o response with tool calls</span>

<span class="n">configurable_model_with_tools</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span>
    <span class="s2">"Which city is hotter today and which is bigger: LA or NY?"</span><span class="p">,</span>
    <span class="n">config</span><span class="o">=</span><span class="p">{</span><span class="s2">"configurable"</span><span class="p">:</span> <span class="p">{</span><span class="s2">"model"</span><span class="p">:</span> <span class="s2">"claude-3-5-sonnet-20240620"</span><span class="p">}}</span>
<span class="p">)</span>
<span class="c1"># Claude-3.5 sonnet response with tools</span>
</pre></div>
</div>
</div>
</details><div class="versionadded">
<p><span class="versionmodified added">Added in version 0.2.7.</span></p>
</div>
<div class="versionchanged">
<p><span class="versionmodified changed">Changed in version 0.2.8: </span>Support for <code class="docutils literal notranslate"><span class="pre">configurable_fields</span></code> and <code class="docutils literal notranslate"><span class="pre">config_prefix</span></code> added.</p>
</div>
<div class="versionchanged">
<p><span class="versionmodified changed">Changed in version 0.2.12: </span>Support for Ollama via langchain-ollama package added
(langchain_ollama.ChatOllama). Previously,
the now-deprecated langchain-community version of Ollama was imported
(langchain_community.chat_models.ChatOllama).</p>
<p>Support for AWS Bedrock models via the Converse API added
(model_provider=‚Äùbedrock_converse‚Äù).</p>
</div>
<div class="versionchanged">
<p><span class="versionmodified changed">Changed in version 0.3.5: </span>Out of beta.</p>
</div>
<div class="versionchanged">
<p><span class="versionmodified changed">Changed in version 0.3.19: </span>Support for Deepseek, IBM, Nvidia, and xAI models added.</p>
</div>
</dd></dl>
<p class="rubric">Examples using init_chat_model</p>
<ul class="simple">
<li><p><a class="reference external" href="https://python.langchain.com/docs/how_to/chat_models_universal_init/">How to init any model in one line</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/how_to/example_selectors_langsmith/">How to select examples from a LangSmith dataset</a></p></li>
</ul>
</section>
</article>
</div>
<dialog id="pst-secondary-sidebar-modal"></dialog>
<div class="bd-sidebar-secondary bd-toc" id="pst-secondary-sidebar"><div class="sidebar-secondary-items sidebar-secondary__inner">
<div class="sidebar-secondary-item">
<div class="page-toc tocsection onthispage" id="pst-page-navigation-heading-2">
<i class="fa-solid fa-list"></i> On this page
  </div>
<nav aria-labelledby="pst-page-navigation-heading-2" class="bd-toc-nav page-toc">
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain.chat_models.base.init_chat_model"><code class="docutils literal notranslate"><span class="pre">init_chat_model()</span></code></a></li>
</ul>
</nav></div>
</div></div>
</div>
<footer class="bd-footer-content">
</footer>
</main>
</div>
</div>
<!-- Scripts loaded after <body> so the DOM is not blocked -->
<script defer="" src="../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer="" src="../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>
<footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
<div class="footer-items__start">
<div class="footer-item">
<p class="copyright">
    
      ¬© Copyright 2025, LangChain Inc.
      <br/>
</p>
</div>
</div>
</div>
</footer>
</body>
</html>