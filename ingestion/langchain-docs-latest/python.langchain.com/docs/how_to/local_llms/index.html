<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-how_to/local_llms" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.5.2">
<title data-rh="true">Run models locally | ü¶úÔ∏èüîó LangChain</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://python.langchain.com/img/brand/theme-image.png"><meta data-rh="true" name="twitter:image" content="https://python.langchain.com/img/brand/theme-image.png"><meta data-rh="true" property="og:url" content="https://python.langchain.com/docs/how_to/local_llms/"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Run models locally | ü¶úÔ∏èüîó LangChain"><meta data-rh="true" name="description" content="Use case"><meta data-rh="true" property="og:description" content="Use case"><link data-rh="true" rel="icon" href="/img/brand/favicon.png"><link data-rh="true" rel="canonical" href="https://python.langchain.com/docs/how_to/local_llms/"><link data-rh="true" rel="alternate" href="https://python.langchain.com/docs/how_to/local_llms/" hreflang="en"><link data-rh="true" rel="alternate" href="https://python.langchain.com/docs/how_to/local_llms/" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://VAU016LAWS-dsn.algolia.net" crossorigin="anonymous"><link rel="search" type="application/opensearchdescription+xml" title="ü¶úÔ∏èüîó LangChain" href="/opensearch.xml">


<script src="/js/google_analytics.js"></script>
<script src="https://www.googletagmanager.com/gtag/js?id=G-9B66JQQH2F" async></script><link rel="stylesheet" href="/assets/css/styles.12df7c44.css">
<script src="/assets/js/runtime~main.9df51359.js" defer="defer"></script>
<script src="/assets/js/main.232f3f22.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();null!==e?t(e):window.matchMedia("(prefers-color-scheme: dark)").matches?t("dark"):(window.matchMedia("(prefers-color-scheme: light)").matches,t("light"))}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}(),document.documentElement.setAttribute("data-announcement-bar-initially-dismissed",function(){try{return"true"===localStorage.getItem("docusaurus.announcement.dismiss")}catch(t){}return!1}())</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><div class="announcementBar_mb4j" style="background-color:#d0c9fe" role="banner"><div class="announcementBarPlaceholder_vyr4"></div><div class="content_knG7 announcementBarContent_xLdY"><strong>Our <a href="https://academy.langchain.com/courses/ambient-agents/?utm_medium=internal&utm_source=docs&utm_campaign=q2-2025_ambient-agents_co" target="_blank">Building Ambient Agents with LangGraph</a> course is now available on LangChain Academy!</strong></div><button type="button" aria-label="Close" class="clean-btn close closeButton_CVFx announcementBarClose_gvF7"><svg viewBox="0 0 15 15" width="14" height="14"><g stroke="currentColor" stroke-width="3.1"><path d="M.75.75l13.5 13.5M14.25.75L.75 14.25"></path></g></svg></button></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/brand/wordmark.png" alt="ü¶úÔ∏èüîó LangChain" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/brand/wordmark-dark.png" alt="ü¶úÔ∏èüîó LangChain" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div></a><a class="navbar__item navbar__link" href="/docs/integrations/providers/">Integrations</a><a href="https://python.langchain.com/api_reference/" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">API Reference</a><div class="navbar__item dropdown dropdown--hoverable"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">More</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/docs/contributing/">Contributing</a></li><li><a class="dropdown__link" href="/docs/people/">People</a></li><li><a class="dropdown__link" href="/docs/troubleshooting/errors/">Error reference</a></li><li><hr class="dropdown-separator" style="margin-top: 0.5rem; margin-bottom: 0.5rem"></li><li><a href="https://docs.smith.langchain.com" target="_blank" rel="noopener noreferrer" class="dropdown__link">LangSmith<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li><a href="https://langchain-ai.github.io/langgraph/" target="_blank" rel="noopener noreferrer" class="dropdown__link">LangGraph<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li><a href="https://smith.langchain.com/hub" target="_blank" rel="noopener noreferrer" class="dropdown__link">LangChain Hub<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li><a href="https://js.langchain.com" target="_blank" rel="noopener noreferrer" class="dropdown__link">LangChain JS/TS<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">v0.3</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/docs/introduction/">v0.3</a></li><li><a href="https://python.langchain.com/v0.2/docs/introduction" target="_blank" rel="noopener noreferrer" class="dropdown__link">v0.2<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li><a href="https://python.langchain.com/v0.1/docs/get_started/introduction" target="_blank" rel="noopener noreferrer" class="dropdown__link">v0.1<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><a href="https://chat.langchain.com" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">üí¨</a><a href="https://github.com/langchain-ai/langchain" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-github-link" aria-label="GitHub repository"></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20" aria-hidden="true"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG menuWithAnnouncementBar_GW3s"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/introduction/">Introduction</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link" href="/docs/tutorials/">Tutorials</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/tutorials/graph/">Build a Question Answering application over a Graph Database</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/tutorials/">Tutorials</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/tutorials/llm_chain/">Build a simple LLM application with chat models and prompt templates</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/tutorials/chatbot/">Build a Chatbot</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/tutorials/qa_chat_history/">Build a Retrieval Augmented Generation (RAG) App: Part 2</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/tutorials/extraction/">Build an Extraction Chain</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/tutorials/agents/">Build an Agent</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/tutorials/classification/">Tagging</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/tutorials/rag/">Build a Retrieval Augmented Generation (RAG) App: Part 1</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/tutorials/retrievers/">Build a semantic search engine</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/tutorials/sql_qa/">Build a Question/Answering system over SQL data</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/tutorials/summarization/">Summarize Text</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--active" href="/docs/how_to/">How-to guides</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/">How-to guides</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/tools_chain/">How to use tools in a chain</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/vectorstore_retriever/">How to use a vectorstore as a retriever</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/chatbots_memory/">How to add memory to chatbots</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/example_selectors/">How to use example selectors</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/graph_semantic/">How to add a semantic layer over graph database</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/parallel/">How to invoke runnables in parallel</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/chat_streaming/">How to stream chat model responses</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/binding/">How to add default invocation args to a Runnable</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/chatbots_retrieval/">How to add retrieval to chatbots</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/few_shot_examples_chat/">How to use few shot examples in chat models</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/function_calling/">How to do tool/function calling</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/installation/">How to install LangChain packages</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/query_few_shot/">How to add examples to the prompt for query analysis</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/few_shot_examples/">How to use few shot examples</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/functions/">How to run custom functions</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/output_parser_structured/">How to use output parsers to parse an LLM response into structured format</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/query_no_queries/">How to handle cases where no queries are generated</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/routing/">How to route between sub-chains</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/structured_output/">How to return structured data from a model</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/summarize_map_reduce/">How to summarize text through parallelization</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/summarize_refine/">How to summarize text through iterative refinement</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/summarize_stuff/">How to summarize text in a single LLM call</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/toolkits/">How to use toolkits</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/tools_prompting/">How to add ad-hoc tool calling capability to LLMs and Chat Models</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/agent_executor/">Build an Agent with AgentExecutor (Legacy)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/graph_constructing/">How to construct knowledge graphs</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/prompts_partial/">How to partially format prompt templates</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/query_multiple_queries/">How to handle multiple queries when doing query analysis</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/tools_builtin/">How to use built-in tools and toolkits</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/passthrough/">How to pass through arguments from one step to the next</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/prompts_composition/">How to compose prompts together</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/query_multiple_retrievers/">How to handle multiple retrievers when doing query analysis</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/assign/">How to add values to a chain&#x27;s state</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/query_constructing_filters/">How to construct filters for query analysis</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/configure/">How to configure runtime chain internals</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/query_high_cardinality/">How deal with high cardinality categoricals when doing query analysis</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/document_loader_custom/">Custom Document Loader</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/MultiQueryRetriever/">How to use the MultiQueryRetriever</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/add_scores_retriever/">How to add scores to retriever results</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/caching_embeddings/">Caching</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/callbacks_async/">How to use callbacks in async environments</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/callbacks_attach/">How to attach callbacks to a runnable</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/callbacks_constructor/">How to propagate callbacks  constructor</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/callbacks_custom_events/">How to dispatch custom callback events</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/callbacks_runtime/">How to pass callbacks in at runtime</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/character_text_splitter/">How to split by character</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/chat_model_caching/">How to cache chat model responses</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/chat_model_rate_limiting/">How to handle rate limits</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/chat_models_universal_init/">How to init any model in one line</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/chat_token_usage_tracking/">How to track token usage in ChatModels</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/chatbots_tools/">How to add tools to chatbots</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/code_splitter/">How to split code</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/contextual_compression/">How to do retrieval with contextual compression</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/convert_runnable_to_tool/">How to convert Runnables to Tools</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/custom_callbacks/">How to create custom callback handlers</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/custom_chat_model/">How to create a custom chat model class</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/custom_embeddings/">Custom Embeddings</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/custom_llm/">How to create a custom LLM class</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/custom_retriever/">Custom Retriever</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/custom_tools/">How to create tools</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/debugging/">How to debug your LLM apps</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/document_loader_csv/">How to load CSVs</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/document_loader_directory/">How to load documents from a directory</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/document_loader_html/">How to load HTML</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/document_loader_json/">How to load JSON</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/document_loader_markdown/">How to load Markdown</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/document_loader_office_file/">How to load Microsoft Office files</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/document_loader_pdf/">How to load PDFs</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/document_loader_web/">How to load web pages</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/dynamic_chain/">How to create a dynamic (self-constructing) chain</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/embed_text/">Text embedding models</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/ensemble_retriever/">How to combine results from multiple retrievers</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/example_selectors_langsmith/">How to select examples from a LangSmith dataset</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/example_selectors_length_based/">How to select examples by length</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/example_selectors_mmr/">How to select examples by maximal marginal relevance (MMR)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/example_selectors_ngram/">How to select examples by n-gram overlap</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/example_selectors_similarity/">How to select examples by similarity</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/extraction_examples/">How to use reference examples when doing extraction</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/extraction_long_text/">How to handle long text when doing extraction</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/extraction_parse/">How to use prompting alone (no tool calling) to do extraction</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/fallbacks/">How to add fallbacks to a runnable</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/filter_messages/">How to filter messages</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/hybrid/">Hybrid Search</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/indexing/">How to use the LangChain indexing API</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/inspect/">How to inspect runnables</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/lcel_cheatsheet/">LangChain Expression Language Cheatsheet</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/llm_caching/">How to cache LLM responses</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/llm_token_usage_tracking/">How to track token usage for LLMs</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/how_to/local_llms/">Run models locally</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/logprobs/">How to get log probabilities</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/long_context_reorder/">How to reorder retrieved results to mitigate the &quot;lost in the middle&quot; effect</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/markdown_header_metadata_splitter/">How to split Markdown by Headers</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/merge_message_runs/">How to merge consecutive messages of the same type</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/message_history/">How to add message history</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/migrate_agent/">How to migrate from legacy LangChain agents to LangGraph</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/multi_vector/">How to retrieve using multiple vectors per document</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/multimodal_inputs/">How to pass multimodal data to models</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/multimodal_prompts/">How to use multimodal prompts</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/output_parser_custom/">How to create a custom Output Parser</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/output_parser_fixing/">How to use the output-fixing parser</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/output_parser_json/">How to parse JSON output</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/output_parser_retry/">How to retry when a parsing error occurs</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/output_parser_string/">How to parse text from message objects</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/output_parser_xml/">How to parse XML output</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/output_parser_yaml/">How to parse YAML output</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/parent_document_retriever/">How to use the Parent Document Retriever</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/pydantic_compatibility/">How to use LangChain with different Pydantic versions</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/qa_chat_history_how_to/">How to add chat history</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/qa_citations/">How to get a RAG application to add citations</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/qa_per_user/">How to do per-user retrieval</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/qa_sources/">How to get your RAG application to return sources</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/qa_streaming/">How to stream results from your RAG application</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/recursive_json_splitter/">How to split JSON data</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/recursive_text_splitter/">How to recursively split text by characters</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/response_metadata/">Response metadata</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/runnable_runtime_secrets/">How to pass runtime secrets to runnables</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/self_query/">How to do &quot;self-querying&quot; retrieval</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/semantic-chunker/">How to split text based on semantic similarity</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/sequence/">How to chain runnables</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/serialization/">How to save and load LangChain objects</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/split_by_token/">How to split text by tokens</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/split_html/">How to split HTML</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/sql_csv/">How to do question answering over CSVs</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/sql_large_db/">How to deal with large databases when doing SQL question-answering</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/sql_prompting/">How to better prompt when doing SQL question-answering</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/sql_query_checking/">How to do query validation as part of SQL question-answering</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/streaming/">How to stream runnables</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/streaming_llm/">How to stream responses from an LLM</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/time_weighted_vectorstore/">How to use a time-weighted vector store retriever</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/tool_artifacts/">How to return artifacts from a tool</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/tool_calling/">How to use chat models to call tools</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/tool_calling_parallel/">How to disable parallel tool calling</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/tool_choice/">How to force models to call a tool</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/tool_configure/">How to access the RunnableConfig from a tool</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/tool_results_pass_to_model/">How to pass tool outputs to chat models</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/tool_runtime/">How to pass run time values to tools</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/tool_stream_events/">How to stream events from a tool</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/tool_streaming/">How to stream tool calls</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/tools_as_openai_functions/">How to convert tools to OpenAI Functions</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/tools_error/">How to handle tool errors</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/tools_few_shot/">How to use few-shot prompting with tool calling</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/tools_human/">How to add a human-in-the-loop for tools</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/tools_model_specific/">How to bind model-specific tools</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/trim_messages/">How to trim messages</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/how_to/vectorstores/">How to create and query vector stores</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link" href="/docs/concepts/">Conceptual guide</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/concepts/agents/">Agents</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/concepts/architecture/">Architecture</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/concepts/async/">Async programming with langchain</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/concepts/callbacks/">Callbacks</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/concepts/chat_history/">Chat history</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/concepts/chat_models/">Chat models</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/concepts/document_loaders/">Document loaders</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/concepts/embedding_models/">Embedding models</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/concepts/evaluation/">Evaluation</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/concepts/example_selectors/">Example selectors</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/concepts/few_shot_prompting/">Few-shot prompting</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/concepts/">Conceptual guide</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/concepts/key_value_stores/">Key-value stores</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/concepts/lcel/">LangChain Expression Language (LCEL)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/concepts/messages/">Messages</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/concepts/multimodality/">Multimodality</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/concepts/output_parsers/">Output parsers</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/concepts/prompt_templates/">Prompt Templates</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/concepts/rag/">Retrieval augmented generation (RAG)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/concepts/retrieval/">Retrieval</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/concepts/retrievers/">Retrievers</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/concepts/runnables/">Runnable interface</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/concepts/streaming/">Streaming</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/concepts/structured_outputs/">Structured outputs</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/concepts/testing/">Testing</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/concepts/text_llms/">String-in, string-out llms</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/concepts/text_splitters/">Text splitters</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/concepts/tokens/">Tokens</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/concepts/tool_calling/">Tool calling</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/concepts/tools/">Tools</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/concepts/tracing/">Tracing</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/concepts/vectorstores/">Vector stores</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/concepts/why_langchain/">Why LangChain?</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link">Ecosystem</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a href="https://docs.smith.langchain.com/" target="_blank" rel="noopener noreferrer" class="menu__link menuExternalLink_NmtK" tabindex="0">ü¶úüõ†Ô∏è LangSmith<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a href="https://langchain-ai.github.io/langgraph/" target="_blank" rel="noopener noreferrer" class="menu__link menuExternalLink_NmtK" tabindex="0">ü¶úüï∏Ô∏è LangGraph<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link">Versions</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/versions/v0_3/">v0.3</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/versions/v0_2/overview/">v0.2</a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/how_to/pydantic_compatibility/">Pydantic compatibility</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link" tabindex="0" href="/docs/versions/migrating_chains/">Migrating from v0.0 chains</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/versions/migrating_chains/">How to migrate from v0.0 chains</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/versions/migrating_chains/constitutional_chain/">Migrating from ConstitutionalChain</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/versions/migrating_chains/conversation_chain/">Migrating from ConversationalChain</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/versions/migrating_chains/conversation_retrieval_chain/">Migrating from ConversationalRetrievalChain</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/versions/migrating_chains/llm_chain/">Migrating from LLMChain</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/versions/migrating_chains/llm_math_chain/">Migrating from LLMMathChain</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/versions/migrating_chains/llm_router_chain/">Migrating from LLMRouterChain</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/versions/migrating_chains/map_reduce_chain/">Migrating from MapReduceDocumentsChain</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/versions/migrating_chains/map_rerank_docs_chain/">Migrating from MapRerankDocumentsChain</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/versions/migrating_chains/multi_prompt_chain/">Migrating from MultiPromptChain</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/versions/migrating_chains/refine_docs_chain/">Migrating from RefineDocumentsChain</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/versions/migrating_chains/retrieval_qa/">Migrating from RetrievalQA</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/versions/migrating_chains/stuff_docs_chain/">Migrating from StuffDocumentsChain</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link" tabindex="0" href="/docs/versions/migrating_memory/">Upgrading to LangGraph memory</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/versions/migrating_memory/">How to migrate to LangGraph memory</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/versions/migrating_memory/chat_history/">How to use BaseChatMessageHistory with LangGraph</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/versions/migrating_memory/conversation_buffer_memory/">Migrating off ConversationBufferMemory or ConversationStringBufferMemory</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/versions/migrating_memory/conversation_buffer_window_memory/">Migrating off ConversationBufferWindowMemory or ConversationTokenBufferMemory</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/versions/migrating_memory/conversation_summary_memory/">Migrating off ConversationSummaryMemory or ConversationSummaryBufferMemory</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/versions/migrating_memory/long_term_memory_agent/">A Long-Term Memory Agent</a></li></ul></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/versions/release_policy/">Release policy</a></li></ul></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/security/">Security Policy</a></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_z5aJ"><div class="docItemContainer_c0TR"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/docs/how_to/"><span itemprop="name">How-to guides</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Run models locally</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div style="display:flex;flex-direction:column;align-items:flex-end;float:right;margin-left:12px"><a target="_blank" href="https://colab.research.google.com/github/langchain-ai/langchain/blob/master/docs/docs/how_to/local_llms.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a><a href="https://github.com/langchain-ai/langchain/blob/master/docs/docs/how_to/local_llms.ipynb" target="_blank"><img src="https://img.shields.io/badge/Open%20on%20GitHub-grey?logo=github&amp;logoColor=white" alt="Open on GitHub"></a></div><div class="theme-doc-markdown markdown"><header><h1>Run models locally</h1></header>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="use-case">Use case<a href="#use-case" class="hash-link" aria-label="Direct link to Use case" title="Direct link to Use case">‚Äã</a></h2>
<p>The popularity of projects like <a href="https://github.com/ggerganov/llama.cpp" target="_blank" rel="noopener noreferrer">llama.cpp</a>, <a href="https://github.com/ollama/ollama" target="_blank" rel="noopener noreferrer">Ollama</a>, <a href="https://github.com/nomic-ai/gpt4all" target="_blank" rel="noopener noreferrer">GPT4All</a>, <a href="https://github.com/Mozilla-Ocho/llamafile" target="_blank" rel="noopener noreferrer">llamafile</a>, and others underscore the demand to run LLMs locally (on your own device).</p>
<p>This has at least two important benefits:</p>
<ol>
<li><code>Privacy</code>: Your data is not sent to a third party, and it is not subject to the terms of service of a commercial service</li>
<li><code>Cost</code>: There is no inference fee, which is important for token-intensive applications (e.g., <a href="https://twitter.com/RLanceMartin/status/1691097659262820352?s=20" target="_blank" rel="noopener noreferrer">long-running simulations</a>, summarization)</li>
</ol>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="overview">Overview<a href="#overview" class="hash-link" aria-label="Direct link to Overview" title="Direct link to Overview">‚Äã</a></h2>
<p>Running an LLM locally requires a few things:</p>
<ol>
<li><code>Open-source LLM</code>: An open-source LLM that can be freely modified and shared</li>
<li><code>Inference</code>: Ability to run this LLM on your device w/ acceptable latency</li>
</ol>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="open-source-llms">Open-source LLMs<a href="#open-source-llms" class="hash-link" aria-label="Direct link to Open-source LLMs" title="Direct link to Open-source LLMs">‚Äã</a></h3>
<p>Users can now gain access to a rapidly growing set of <a href="https://cameronrwolfe.substack.com/p/the-history-of-open-source-llms-better" target="_blank" rel="noopener noreferrer">open-source LLMs</a>.</p>
<p>These LLMs can be assessed across at least two dimensions (see figure):</p>
<ol>
<li><code>Base model</code>: What is the base-model and how was it trained?</li>
<li><code>Fine-tuning approach</code>: Was the base-model fine-tuned and, if so, what <a href="https://cameronrwolfe.substack.com/p/beyond-llama-the-power-of-open-llms#%C2%A7alpaca-an-instruction-following-llama-model" target="_blank" rel="noopener noreferrer">set of instructions</a> was used?</li>
</ol>
<p><img decoding="async" loading="lazy" alt="Image description" src="/assets/images/OSS_LLM_overview-9444c9793c76bd4785a5b0cd020c14ef.png" width="1689" height="792" class="img_ev3q"></p>
<p>The relative performance of these models can be assessed using several leaderboards, including:</p>
<ol>
<li><a href="https://chat.lmsys.org/?arena" target="_blank" rel="noopener noreferrer">LmSys</a></li>
<li><a href="https://gpt4all.io/index.html" target="_blank" rel="noopener noreferrer">GPT4All</a></li>
<li><a href="https://huggingface.co/spaces/lmsys/chatbot-arena-leaderboard" target="_blank" rel="noopener noreferrer">HuggingFace</a></li>
</ol>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="inference">Inference<a href="#inference" class="hash-link" aria-label="Direct link to Inference" title="Direct link to Inference">‚Äã</a></h3>
<p>A few frameworks for this have emerged to support inference of open-source LLMs on various devices:</p>
<ol>
<li><a href="https://github.com/ggerganov/llama.cpp" target="_blank" rel="noopener noreferrer"><code>llama.cpp</code></a>: C++ implementation of llama inference code with <a href="https://finbarr.ca/how-is-llama-cpp-possible/" target="_blank" rel="noopener noreferrer">weight optimization / quantization</a></li>
<li><a href="https://docs.gpt4all.io/index.html" target="_blank" rel="noopener noreferrer"><code>gpt4all</code></a>: Optimized C backend for inference</li>
<li><a href="https://ollama.ai/" target="_blank" rel="noopener noreferrer"><code>Ollama</code></a>: Bundles model weights and environment into an app that runs on device and serves the LLM</li>
<li><a href="https://github.com/Mozilla-Ocho/llamafile" target="_blank" rel="noopener noreferrer"><code>llamafile</code></a>: Bundles model weights and everything needed to run the model in a single file, allowing you to run the LLM locally from this file without any additional installation steps</li>
</ol>
<p>In general, these frameworks will do a few things:</p>
<ol>
<li><code>Quantization</code>: Reduce the memory footprint of the raw model weights</li>
<li><code>Efficient implementation for inference</code>: Support inference on consumer hardware (e.g., CPU or laptop GPU)</li>
</ol>
<p>In particular, see <a href="https://finbarr.ca/how-is-llama-cpp-possible/" target="_blank" rel="noopener noreferrer">this excellent post</a> on the importance of quantization.</p>
<p><img decoding="async" loading="lazy" alt="Image description" src="/assets/images/llama-memory-weights-aaccef5df087e993b0f46277500039b6.png" width="639" height="170" class="img_ev3q"></p>
<p>With less precision, we radically decrease the memory needed to store the LLM in memory.</p>
<p>In addition, we can see the importance of GPU memory bandwidth <a href="https://docs.google.com/spreadsheets/d/1OehfHHNSn66BP2h3Bxp2NJTVX97icU0GmCXF6pK23H8/edit#gid=0" target="_blank" rel="noopener noreferrer">sheet</a>!</p>
<p>A Mac M2 Max is 5-6x faster than a M1 for inference due to the larger GPU memory bandwidth.</p>
<p><img decoding="async" loading="lazy" alt="Image description" src="/assets/images/llama_t_put-c6f0ea201a6dd508999170325cd6804a.png" width="599" height="176" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="formatting-prompts">Formatting prompts<a href="#formatting-prompts" class="hash-link" aria-label="Direct link to Formatting prompts" title="Direct link to Formatting prompts">‚Äã</a></h3>
<p>Some providers have <a href="/docs/concepts/chat_models/">chat model</a> wrappers that takes care of formatting your input prompt for the specific local model you&#x27;re using. However, if you are prompting local models with a <a href="/docs/concepts/text_llms/">text-in/text-out LLM</a> wrapper, you may need to use a prompt tailored for your specific model.</p>
<p>This can <a href="https://huggingface.co/blog/llama2#how-to-prompt-llama-2" target="_blank" rel="noopener noreferrer">require the inclusion of special tokens</a>. <a href="https://smith.langchain.com/hub/rlm/rag-prompt-llama" target="_blank" rel="noopener noreferrer">Here&#x27;s an example for LLaMA 2</a>.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="quickstart">Quickstart<a href="#quickstart" class="hash-link" aria-label="Direct link to Quickstart" title="Direct link to Quickstart">‚Äã</a></h2>
<p><a href="https://ollama.ai/" target="_blank" rel="noopener noreferrer"><code>Ollama</code></a> is one way to easily run inference on macOS.</p>
<p>The instructions <a href="https://github.com/jmorganca/ollama?tab=readme-ov-file#ollama" target="_blank" rel="noopener noreferrer">here</a> provide details, which we summarize:</p>
<ul>
<li><a href="https://ollama.ai/download" target="_blank" rel="noopener noreferrer">Download and run</a> the app</li>
<li>From command line, fetch a model from this <a href="https://github.com/jmorganca/ollama" target="_blank" rel="noopener noreferrer">list of options</a>: e.g., <code>ollama pull llama3.1:8b</code></li>
<li>When the app is running, all models are automatically served on <code>localhost:11434</code></li>
</ul>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#F5F5F5"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token operator" style="color:rgb(0, 0, 0)">%</span><span class="token plain">pip install </span><span class="token operator" style="color:rgb(0, 0, 0)">-</span><span class="token plain">qU langchain_ollama</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#F5F5F5"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token keyword" style="color:rgb(0, 0, 255)">from</span><span class="token plain"> langchain_ollama </span><span class="token keyword" style="color:rgb(0, 0, 255)">import</span><span class="token plain"> OllamaLLM</span><br></span><span class="token-line" style="color:#000000"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">llm </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> OllamaLLM</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token plain">model</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token string" style="color:rgb(163, 21, 21)">&quot;llama3.1:8b&quot;</span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">llm</span><span class="token punctuation" style="color:rgb(4, 81, 165)">.</span><span class="token plain">invoke</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token string" style="color:rgb(163, 21, 21)">&quot;The first man on the moon was ...&quot;</span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><div style="padding-top:1.3rem;background:var(--prism-background-color);color:var(--prism-color);margin-top:calc(-1 * var(--ifm-leading) - 5px);margin-bottom:var(--ifm-leading);box-shadow:var(--ifm-global-shadow-lw);border-bottom-left-radius:var(--ifm-code-border-radius);border-bottom-right-radius:var(--ifm-code-border-radius)"><b style="padding-left:0.65rem;margin-bottom:0.45rem;margin-right:0.5rem">API Reference:</b><span><a href="https://python.langchain.com/api_reference/ollama/llms/langchain_ollama.llms.OllamaLLM.html">OllamaLLM</a></span></div>
<div class="language-output codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-output codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#F5F5F5"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">&#x27;...Neil Armstrong!\n\nOn July 20, 1969, Neil Armstrong became the first person to set foot on the lunar surface, famously declaring &quot;That\&#x27;s one small step for man, one giant leap for mankind&quot; as he stepped off the lunar module Eagle onto the Moon\&#x27;s surface.\n\nWould you like to know more about the Apollo 11 mission or Neil Armstrong\&#x27;s achievements?&#x27;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Stream tokens as they are being generated:</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#F5F5F5"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token keyword" style="color:rgb(0, 0, 255)">for</span><span class="token plain"> chunk </span><span class="token keyword" style="color:rgb(0, 0, 255)">in</span><span class="token plain"> llm</span><span class="token punctuation" style="color:rgb(4, 81, 165)">.</span><span class="token plain">stream</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token string" style="color:rgb(163, 21, 21)">&quot;The first man on the moon was ...&quot;</span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><span class="token punctuation" style="color:rgb(4, 81, 165)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    </span><span class="token keyword" style="color:rgb(0, 0, 255)">print</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token plain">chunk</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"> end</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token string" style="color:rgb(163, 21, 21)">&quot;|&quot;</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"> flush</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token boolean">True</span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="language-output codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-output codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#F5F5F5"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">...|</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">``````output</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">Neil| Armstrong|,| an| American| astronaut|.| He| stepped| out| of| the| lunar| module| Eagle| and| onto| the| surface| of| the| Moon| on| July| |20|,| |196|9|,| famously| declaring|:| &quot;|That|&#x27;s| one| small| step| for| man|,| one| giant| leap| for| mankind|.&quot;||</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Ollama also includes a chat model wrapper that handles formatting conversation turns:</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#F5F5F5"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token keyword" style="color:rgb(0, 0, 255)">from</span><span class="token plain"> langchain_ollama </span><span class="token keyword" style="color:rgb(0, 0, 255)">import</span><span class="token plain"> ChatOllama</span><br></span><span class="token-line" style="color:#000000"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">chat_model </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> ChatOllama</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token plain">model</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token string" style="color:rgb(163, 21, 21)">&quot;llama3.1:8b&quot;</span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">chat_model</span><span class="token punctuation" style="color:rgb(4, 81, 165)">.</span><span class="token plain">invoke</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token string" style="color:rgb(163, 21, 21)">&quot;Who was the first man on the moon?&quot;</span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><div style="padding-top:1.3rem;background:var(--prism-background-color);color:var(--prism-color);margin-top:calc(-1 * var(--ifm-leading) - 5px);margin-bottom:var(--ifm-leading);box-shadow:var(--ifm-global-shadow-lw);border-bottom-left-radius:var(--ifm-code-border-radius);border-bottom-right-radius:var(--ifm-code-border-radius)"><b style="padding-left:0.65rem;margin-bottom:0.45rem;margin-right:0.5rem">API Reference:</b><span><a href="https://python.langchain.com/api_reference/ollama/chat_models/langchain_ollama.chat_models.ChatOllama.html">ChatOllama</a></span></div>
<div class="language-output codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-output codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#F5F5F5"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">AIMessage(content=&#x27;The answer is a historic one!\n\nThe first man to walk on the Moon was Neil Armstrong, an American astronaut and commander of the Apollo 11 mission. On July 20, 1969, Armstrong stepped out of the lunar module Eagle onto the surface of the Moon, famously declaring:\n\n&quot;That\&#x27;s one small step for man, one giant leap for mankind.&quot;\n\nArmstrong was followed by fellow astronaut Edwin &quot;Buzz&quot; Aldrin, who also walked on the Moon during the mission. Michael Collins remained in orbit around the Moon in the command module Columbia.\n\nNeil Armstrong passed away on August 25, 2012, but his legacy as a pioneering astronaut and engineer continues to inspire people around the world!&#x27;, response_metadata={&#x27;model&#x27;: &#x27;llama3.1:8b&#x27;, &#x27;created_at&#x27;: &#x27;2024-08-01T00:38:29.176717Z&#x27;, &#x27;message&#x27;: {&#x27;role&#x27;: &#x27;assistant&#x27;, &#x27;content&#x27;: &#x27;&#x27;}, &#x27;done_reason&#x27;: &#x27;stop&#x27;, &#x27;done&#x27;: True, &#x27;total_duration&#x27;: 10681861417, &#x27;load_duration&#x27;: 34270292, &#x27;prompt_eval_count&#x27;: 19, &#x27;prompt_eval_duration&#x27;: 6209448000, &#x27;eval_count&#x27;: 141, &#x27;eval_duration&#x27;: 4432022000}, id=&#x27;run-7bed57c5-7f54-4092-912c-ae49073dcd48-0&#x27;, usage_metadata={&#x27;input_tokens&#x27;: 19, &#x27;output_tokens&#x27;: 141, &#x27;total_tokens&#x27;: 160})</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="environment">Environment<a href="#environment" class="hash-link" aria-label="Direct link to Environment" title="Direct link to Environment">‚Äã</a></h2>
<p>Inference speed is a challenge when running models locally (see above).</p>
<p>To minimize latency, it is desirable to run models locally on GPU, which ships with many consumer laptops <a href="https://www.apple.com/newsroom/2022/06/apple-unveils-m2-with-breakthrough-performance-and-capabilities/" target="_blank" rel="noopener noreferrer">e.g., Apple devices</a>.</p>
<p>And even with GPU, the available GPU memory bandwidth (as noted above) is important.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="running-apple-silicon-gpu">Running Apple silicon GPU<a href="#running-apple-silicon-gpu" class="hash-link" aria-label="Direct link to Running Apple silicon GPU" title="Direct link to Running Apple silicon GPU">‚Äã</a></h3>
<p><code>Ollama</code> and <a href="https://github.com/Mozilla-Ocho/llamafile?tab=readme-ov-file#gpu-support" target="_blank" rel="noopener noreferrer"><code>llamafile</code></a> will automatically utilize the GPU on Apple devices.</p>
<p>Other frameworks require the user to set up the environment to utilize the Apple GPU.</p>
<p>For example, <code>llama.cpp</code> python bindings can be configured to use the GPU via <a href="https://developer.apple.com/metal/" target="_blank" rel="noopener noreferrer">Metal</a>.</p>
<p>Metal is a graphics and compute API created by Apple providing near-direct access to the GPU.</p>
<p>See the <a href="/docs/integrations/llms/llamacpp/"><code>llama.cpp</code></a> setup <a href="https://github.com/abetlen/llama-cpp-python/blob/main/docs/install/macos.md" target="_blank" rel="noopener noreferrer">here</a> to enable this.</p>
<p>In particular, ensure that conda is using the correct virtual environment that you created (<code>miniforge3</code>).</p>
<p>E.g., for me:</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#F5F5F5"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">conda activate /Users/rlm/miniforge3/envs/llama</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>With the above confirmed, then:</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#F5F5F5"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">CMAKE_ARGS=&quot;-DLLAMA_METAL=on&quot; FORCE_CMAKE=1 pip install -U llama-cpp-python --no-cache-dir</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="llms">LLMs<a href="#llms" class="hash-link" aria-label="Direct link to LLMs" title="Direct link to LLMs">‚Äã</a></h2>
<p>There are various ways to gain access to quantized model weights.</p>
<ol>
<li><a href="https://huggingface.co/TheBloke" target="_blank" rel="noopener noreferrer"><code>HuggingFace</code></a> - Many quantized model are available for download and can be run with framework such as <a href="https://github.com/ggerganov/llama.cpp" target="_blank" rel="noopener noreferrer"><code>llama.cpp</code></a>. You can also download models in <a href="https://huggingface.co/models?other=llamafile" target="_blank" rel="noopener noreferrer"><code>llamafile</code> format</a> from HuggingFace.</li>
<li><a href="https://gpt4all.io/index.html" target="_blank" rel="noopener noreferrer"><code>gpt4all</code></a> - The model explorer offers a leaderboard of metrics and associated quantized models available for download</li>
<li><a href="https://github.com/jmorganca/ollama" target="_blank" rel="noopener noreferrer"><code>Ollama</code></a> - Several models can be accessed directly via <code>pull</code></li>
</ol>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="ollama">Ollama<a href="#ollama" class="hash-link" aria-label="Direct link to Ollama" title="Direct link to Ollama">‚Äã</a></h3>
<p>With <a href="https://github.com/jmorganca/ollama" target="_blank" rel="noopener noreferrer">Ollama</a>, fetch a model via <code>ollama pull &lt;model family&gt;:&lt;tag&gt;</code>:</p>
<ul>
<li>E.g., for Llama 2 7b: <code>ollama pull llama2</code> will download the most basic version of the model (e.g., smallest # parameters and 4 bit quantization)</li>
<li>We can also specify a particular version from the <a href="https://github.com/jmorganca/ollama?tab=readme-ov-file#model-library" target="_blank" rel="noopener noreferrer">model list</a>, e.g., <code>ollama pull llama2:13b</code></li>
<li>See the full set of parameters on the <a href="https://python.langchain.com/api_reference/community/llms/langchain_community.llms.ollama.Ollama.html" target="_blank" rel="noopener noreferrer">API reference page</a></li>
</ul>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#F5F5F5"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">llm </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> OllamaLLM</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token plain">model</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token string" style="color:rgb(163, 21, 21)">&quot;llama2:13b&quot;</span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">llm</span><span class="token punctuation" style="color:rgb(4, 81, 165)">.</span><span class="token plain">invoke</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token string" style="color:rgb(163, 21, 21)">&quot;The first man on the moon was ... think step by step&quot;</span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="language-output codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-output codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#F5F5F5"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">&#x27; Sure! Here\&#x27;s the answer, broken down step by step:\n\nThe first man on the moon was... Neil Armstrong.\n\nHere\&#x27;s how I arrived at that answer:\n\n1. The first manned mission to land on the moon was Apollo 11.\n2. The mission included three astronauts: Neil Armstrong, Edwin &quot;Buzz&quot; Aldrin, and Michael Collins.\n3. Neil Armstrong was the mission commander and the first person to set foot on the moon.\n4. On July 20, 1969, Armstrong stepped out of the lunar module Eagle and onto the moon\&#x27;s surface, famously declaring &quot;That\&#x27;s one small step for man, one giant leap for mankind.&quot;\n\nSo, the first man on the moon was Neil Armstrong!&#x27;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="llamacpp">Llama.cpp<a href="#llamacpp" class="hash-link" aria-label="Direct link to Llama.cpp" title="Direct link to Llama.cpp">‚Äã</a></h3>
<p>Llama.cpp is compatible with a <a href="https://github.com/ggerganov/llama.cpp" target="_blank" rel="noopener noreferrer">broad set of models</a>.</p>
<p>For example, below we run inference on <code>llama2-13b</code> with 4 bit quantization downloaded from <a href="https://huggingface.co/TheBloke/Llama-2-13B-GGML/tree/main" target="_blank" rel="noopener noreferrer">HuggingFace</a>.</p>
<p>As noted above, see the <a href="https://python.langchain.com/api_reference/langchain/llms/langchain.llms.llamacpp.LlamaCpp.html?highlight=llamacpp#langchain.llms.llamacpp.LlamaCpp" target="_blank" rel="noopener noreferrer">API reference</a> for the full set of parameters.</p>
<p>From the <a href="https://python.langchain.com/api_reference/community/llms/langchain_community.llms.llamacpp.LlamaCpp.html" target="_blank" rel="noopener noreferrer">llama.cpp API reference docs</a>, a few are worth commenting on:</p>
<p><code>n_gpu_layers</code>: number of layers to be loaded into GPU memory</p>
<ul>
<li>Value: 1</li>
<li>Meaning: Only one layer of the model will be loaded into GPU memory (1 is often sufficient).</li>
</ul>
<p><code>n_batch</code>: number of tokens the model should process in parallel</p>
<ul>
<li>Value: n_batch</li>
<li>Meaning: It&#x27;s recommended to choose a value between 1 and n_ctx (which in this case is set to 2048)</li>
</ul>
<p><code>n_ctx</code>: Token context window</p>
<ul>
<li>Value: 2048</li>
<li>Meaning: The model will consider a window of 2048 tokens at a time</li>
</ul>
<p><code>f16_kv</code>: whether the model should use half-precision for the key/value cache</p>
<ul>
<li>Value: True</li>
<li>Meaning: The model will use half-precision, which can be more memory efficient; Metal only supports True.</li>
</ul>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#F5F5F5"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token operator" style="color:rgb(0, 0, 0)">%</span><span class="token plain">env CMAKE_ARGS</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token string" style="color:rgb(163, 21, 21)">&quot;-DLLAMA_METAL=on&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain"></span><span class="token operator" style="color:rgb(0, 0, 0)">%</span><span class="token plain">env FORCE_CMAKE</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token number" style="color:rgb(9, 134, 88)">1</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain"></span><span class="token operator" style="color:rgb(0, 0, 0)">%</span><span class="token plain">pip install </span><span class="token operator" style="color:rgb(0, 0, 0)">-</span><span class="token operator" style="color:rgb(0, 0, 0)">-</span><span class="token plain">upgrade </span><span class="token operator" style="color:rgb(0, 0, 0)">-</span><span class="token operator" style="color:rgb(0, 0, 0)">-</span><span class="token plain">quiet  llama</span><span class="token operator" style="color:rgb(0, 0, 0)">-</span><span class="token plain">cpp</span><span class="token operator" style="color:rgb(0, 0, 0)">-</span><span class="token plain">python </span><span class="token operator" style="color:rgb(0, 0, 0)">-</span><span class="token operator" style="color:rgb(0, 0, 0)">-</span><span class="token plain">no</span><span class="token operator" style="color:rgb(0, 0, 0)">-</span><span class="token plain">cache</span><span class="token operator" style="color:rgb(0, 0, 0)">-</span><span class="token builtin" style="color:rgb(0, 112, 193)">dir</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#F5F5F5"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token keyword" style="color:rgb(0, 0, 255)">from</span><span class="token plain"> langchain_community</span><span class="token punctuation" style="color:rgb(4, 81, 165)">.</span><span class="token plain">llms </span><span class="token keyword" style="color:rgb(0, 0, 255)">import</span><span class="token plain"> LlamaCpp</span><br></span><span class="token-line" style="color:#000000"><span class="token plain"></span><span class="token keyword" style="color:rgb(0, 0, 255)">from</span><span class="token plain"> langchain_core</span><span class="token punctuation" style="color:rgb(4, 81, 165)">.</span><span class="token plain">callbacks </span><span class="token keyword" style="color:rgb(0, 0, 255)">import</span><span class="token plain"> CallbackManager</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"> StreamingStdOutCallbackHandler</span><br></span><span class="token-line" style="color:#000000"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">llm </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> LlamaCpp</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    model_path</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token string" style="color:rgb(163, 21, 21)">&quot;/Users/rlm/Desktop/Code/llama.cpp/models/openorca-platypus2-13b.gguf.q4_0.bin&quot;</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    n_gpu_layers</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token number" style="color:rgb(9, 134, 88)">1</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    n_batch</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token number" style="color:rgb(9, 134, 88)">512</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    n_ctx</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token number" style="color:rgb(9, 134, 88)">2048</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    f16_kv</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token boolean">True</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    callback_manager</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain">CallbackManager</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token punctuation" style="color:rgb(4, 81, 165)">[</span><span class="token plain">StreamingStdOutCallbackHandler</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><span class="token punctuation" style="color:rgb(4, 81, 165)">]</span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    verbose</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token boolean">True</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain"></span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><div style="padding-top:1.3rem;background:var(--prism-background-color);color:var(--prism-color);margin-top:calc(-1 * var(--ifm-leading) - 5px);margin-bottom:var(--ifm-leading);box-shadow:var(--ifm-global-shadow-lw);border-bottom-left-radius:var(--ifm-code-border-radius);border-bottom-right-radius:var(--ifm-code-border-radius)"><b style="padding-left:0.65rem;margin-bottom:0.45rem;margin-right:0.5rem">API Reference:</b><span><a href="https://python.langchain.com/api_reference/community/llms/langchain_community.llms.llamacpp.LlamaCpp.html">LlamaCpp</a> | </span><span><a href="https://python.langchain.com/api_reference/core/callbacks/langchain_core.callbacks.manager.CallbackManager.html">CallbackManager</a> | </span><span><a href="https://python.langchain.com/api_reference/core/callbacks/langchain_core.callbacks.streaming_stdout.StreamingStdOutCallbackHandler.html">StreamingStdOutCallbackHandler</a></span></div>
<p>The console log will show the below to indicate Metal was enabled properly from steps above:</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#F5F5F5"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">ggml_metal_init: allocating</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">ggml_metal_init: using MPS</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#F5F5F5"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">llm</span><span class="token punctuation" style="color:rgb(4, 81, 165)">.</span><span class="token plain">invoke</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token string" style="color:rgb(163, 21, 21)">&quot;The first man on the moon was ... Let&#x27;s think step by step&quot;</span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="language-output codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-output codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#F5F5F5"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">Llama.generate: prefix-match hit</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">``````output</span><br></span><span class="token-line" style="color:#000000"><span class="token plain"> and use logical reasoning to figure out who the first man on the moon was.</span><br></span><span class="token-line" style="color:#000000"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">Here are some clues:</span><br></span><span class="token-line" style="color:#000000"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">1. The first man on the moon was an American.</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">2. He was part of the Apollo 11 mission.</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">3. He stepped out of the lunar module and became the first person to set foot on the moon&#x27;s surface.</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">4. His last name is Armstrong.</span><br></span><span class="token-line" style="color:#000000"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">Now, let&#x27;s use our reasoning skills to figure out who the first man on the moon was. Based on clue #1, we know that the first man on the moon was an American. Clue #2 tells us that he was part of the Apollo 11 mission. Clue #3 reveals that he was the first person to set foot on the moon&#x27;s surface. And finally, clue #4 gives us his last name: Armstrong.</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">Therefore, the first man on the moon was Neil Armstrong!</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">``````output</span><br></span><span class="token-line" style="color:#000000"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">llama_print_timings:        load time =  9623.21 ms</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">llama_print_timings:      sample time =   143.77 ms /   203 runs   (    0.71 ms per token,  1412.01 tokens per second)</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">llama_print_timings: prompt eval time =   485.94 ms /     7 tokens (   69.42 ms per token,    14.40 tokens per second)</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">llama_print_timings:        eval time =  6385.16 ms /   202 runs   (   31.61 ms per token,    31.64 tokens per second)</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">llama_print_timings:       total time =  7279.28 ms</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="language-output codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-output codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#F5F5F5"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">&quot; and use logical reasoning to figure out who the first man on the moon was.\n\nHere are some clues:\n\n1. The first man on the moon was an American.\n2. He was part of the Apollo 11 mission.\n3. He stepped out of the lunar module and became the first person to set foot on the moon&#x27;s surface.\n4. His last name is Armstrong.\n\nNow, let&#x27;s use our reasoning skills to figure out who the first man on the moon was. Based on clue #1, we know that the first man on the moon was an American. Clue #2 tells us that he was part of the Apollo 11 mission. Clue #3 reveals that he was the first person to set foot on the moon&#x27;s surface. And finally, clue #4 gives us his last name: Armstrong.\nTherefore, the first man on the moon was Neil Armstrong!&quot;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="gpt4all">GPT4All<a href="#gpt4all" class="hash-link" aria-label="Direct link to GPT4All" title="Direct link to GPT4All">‚Äã</a></h3>
<p>We can use model weights downloaded from <a href="/docs/integrations/llms/gpt4all/">GPT4All</a> model explorer.</p>
<p>Similar to what is shown above, we can run inference and use <a href="https://python.langchain.com/api_reference/community/llms/langchain_community.llms.gpt4all.GPT4All.html" target="_blank" rel="noopener noreferrer">the API reference</a> to set parameters of interest.</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#F5F5F5"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token operator" style="color:rgb(0, 0, 0)">%</span><span class="token plain">pip install gpt4all</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#F5F5F5"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token keyword" style="color:rgb(0, 0, 255)">from</span><span class="token plain"> langchain_community</span><span class="token punctuation" style="color:rgb(4, 81, 165)">.</span><span class="token plain">llms </span><span class="token keyword" style="color:rgb(0, 0, 255)">import</span><span class="token plain"> GPT4All</span><br></span><span class="token-line" style="color:#000000"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">llm </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> GPT4All</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    model</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token string" style="color:rgb(163, 21, 21)">&quot;/Users/rlm/Desktop/Code/gpt4all/models/nous-hermes-13b.ggmlv3.q4_0.bin&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain"></span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><div style="padding-top:1.3rem;background:var(--prism-background-color);color:var(--prism-color);margin-top:calc(-1 * var(--ifm-leading) - 5px);margin-bottom:var(--ifm-leading);box-shadow:var(--ifm-global-shadow-lw);border-bottom-left-radius:var(--ifm-code-border-radius);border-bottom-right-radius:var(--ifm-code-border-radius)"><b style="padding-left:0.65rem;margin-bottom:0.45rem;margin-right:0.5rem">API Reference:</b><span><a href="https://python.langchain.com/api_reference/community/llms/langchain_community.llms.gpt4all.GPT4All.html">GPT4All</a></span></div>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#F5F5F5"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">llm</span><span class="token punctuation" style="color:rgb(4, 81, 165)">.</span><span class="token plain">invoke</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token string" style="color:rgb(163, 21, 21)">&quot;The first man on the moon was ... Let&#x27;s think step by step&quot;</span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="language-output codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-output codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#F5F5F5"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">&quot;.\n1) The United States decides to send a manned mission to the moon.2) They choose their best astronauts and train them for this specific mission.3) They build a spacecraft that can take humans to the moon, called the Lunar Module (LM).4) They also create a larger spacecraft, called the Saturn V rocket, which will launch both the LM and the Command Service Module (CSM), which will carry the astronauts into orbit.5) The mission is planned down to the smallest detail: from the trajectory of the rockets to the exact movements of the astronauts during their moon landing.6) On July 16, 1969, the Saturn V rocket launches from Kennedy Space Center in Florida, carrying the Apollo 11 mission crew into space.7) After one and a half orbits around the Earth, the LM separates from the CSM and begins its descent to the moon&#x27;s surface.8) On July 20, 1969, at 2:56 pm EDT (GMT-4), Neil Armstrong becomes the first man on the moon. He speaks these&quot;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="llamafile">llamafile<a href="#llamafile" class="hash-link" aria-label="Direct link to llamafile" title="Direct link to llamafile">‚Äã</a></h3>
<p>One of the simplest ways to run an LLM locally is using a <a href="https://github.com/Mozilla-Ocho/llamafile" target="_blank" rel="noopener noreferrer">llamafile</a>. All you need to do is:</p>
<ol>
<li>Download a llamafile from <a href="https://huggingface.co/models?other=llamafile" target="_blank" rel="noopener noreferrer">HuggingFace</a></li>
<li>Make the file executable</li>
<li>Run the file</li>
</ol>
<p>llamafiles bundle model weights and a <a href="https://github.com/Mozilla-Ocho/llamafile?tab=readme-ov-file#technical-details" target="_blank" rel="noopener noreferrer">specially-compiled</a> version of <a href="https://github.com/ggerganov/llama.cpp" target="_blank" rel="noopener noreferrer"><code>llama.cpp</code></a> into a single file that can run on most computers without any additional dependencies. They also come with an embedded inference server that provides an <a href="https://github.com/Mozilla-Ocho/llamafile/blob/main/llama.cpp/server/README.md#api-endpoints" target="_blank" rel="noopener noreferrer">API</a> for interacting with your model.</p>
<p>Here&#x27;s a simple bash script that shows all 3 setup steps:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#F5F5F5"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain"># Download a llamafile from HuggingFace</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">wget https://huggingface.co/jartine/TinyLlama-1.1B-Chat-v1.0-GGUF/resolve/main/TinyLlama-1.1B-Chat-v1.0.Q5_K_M.llamafile</span><br></span><span class="token-line" style="color:#000000"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain"># Make the file executable. On Windows, instead just rename the file to end in &quot;.exe&quot;.</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">chmod +x TinyLlama-1.1B-Chat-v1.0.Q5_K_M.llamafile</span><br></span><span class="token-line" style="color:#000000"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain"># Start the model server. Listens at http://localhost:8080 by default.</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">./TinyLlama-1.1B-Chat-v1.0.Q5_K_M.llamafile --server --nobrowser</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>After you run the above setup steps, you can use LangChain to interact with your model:</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#F5F5F5"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token keyword" style="color:rgb(0, 0, 255)">from</span><span class="token plain"> langchain_community</span><span class="token punctuation" style="color:rgb(4, 81, 165)">.</span><span class="token plain">llms</span><span class="token punctuation" style="color:rgb(4, 81, 165)">.</span><span class="token plain">llamafile </span><span class="token keyword" style="color:rgb(0, 0, 255)">import</span><span class="token plain"> Llamafile</span><br></span><span class="token-line" style="color:#000000"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">llm </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> Llamafile</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">llm</span><span class="token punctuation" style="color:rgb(4, 81, 165)">.</span><span class="token plain">invoke</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token string" style="color:rgb(163, 21, 21)">&quot;The first man on the moon was ... Let&#x27;s think step by step.&quot;</span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><div style="padding-top:1.3rem;background:var(--prism-background-color);color:var(--prism-color);margin-top:calc(-1 * var(--ifm-leading) - 5px);margin-bottom:var(--ifm-leading);box-shadow:var(--ifm-global-shadow-lw);border-bottom-left-radius:var(--ifm-code-border-radius);border-bottom-right-radius:var(--ifm-code-border-radius)"><b style="padding-left:0.65rem;margin-bottom:0.45rem;margin-right:0.5rem">API Reference:</b><span><a href="https://python.langchain.com/api_reference/community/llms/langchain_community.llms.llamafile.Llamafile.html">Llamafile</a></span></div>
<div class="language-output codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-output codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#F5F5F5"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">&quot;\nFirstly, let&#x27;s imagine the scene where Neil Armstrong stepped onto the moon. This happened in 1969. The first man on the moon was Neil Armstrong. We already know that.\n2nd, let&#x27;s take a step back. Neil Armstrong didn&#x27;t have any special powers. He had to land his spacecraft safely on the moon without injuring anyone or causing any damage. If he failed to do this, he would have been killed along with all those people who were on board the spacecraft.\n3rd, let&#x27;s imagine that Neil Armstrong successfully landed his spacecraft on the moon and made it back to Earth safely. The next step was for him to be hailed as a hero by his people back home. It took years before Neil Armstrong became an American hero.\n4th, let&#x27;s take another step back. Let&#x27;s imagine that Neil Armstrong wasn&#x27;t hailed as a hero, and instead, he was just forgotten. This happened in the 1970s. Neil Armstrong wasn&#x27;t recognized for his remarkable achievement on the moon until after he died.\n5th, let&#x27;s take another step back. Let&#x27;s imagine that Neil Armstrong didn&#x27;t die in the 1970s and instead, lived to be a hundred years old. This happened in 2036. In the year 2036, Neil Armstrong would have been a centenarian.\nNow, let&#x27;s think about the present. Neil Armstrong is still alive. He turned 95 years old on July 20th, 2018. If he were to die now, his achievement of becoming the first human being to set foot on the moon would remain an unforgettable moment in history.\nI hope this helps you understand the significance and importance of Neil Armstrong&#x27;s achievement on the moon!&quot;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="prompts">Prompts<a href="#prompts" class="hash-link" aria-label="Direct link to Prompts" title="Direct link to Prompts">‚Äã</a></h2>
<p>Some LLMs will benefit from specific prompts.</p>
<p>For example, LLaMA will use <a href="https://twitter.com/RLanceMartin/status/1681879318493003776?s=20" target="_blank" rel="noopener noreferrer">special tokens</a>.</p>
<p>We can use <code>ConditionalPromptSelector</code> to set prompt based on the model type.</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#F5F5F5"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token comment" style="color:rgb(0, 128, 0)"># Set our LLM</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">llm </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> LlamaCpp</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    model_path</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token string" style="color:rgb(163, 21, 21)">&quot;/Users/rlm/Desktop/Code/llama.cpp/models/openorca-platypus2-13b.gguf.q4_0.bin&quot;</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    n_gpu_layers</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token number" style="color:rgb(9, 134, 88)">1</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    n_batch</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token number" style="color:rgb(9, 134, 88)">512</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    n_ctx</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token number" style="color:rgb(9, 134, 88)">2048</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    f16_kv</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token boolean">True</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    callback_manager</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain">CallbackManager</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token punctuation" style="color:rgb(4, 81, 165)">[</span><span class="token plain">StreamingStdOutCallbackHandler</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><span class="token punctuation" style="color:rgb(4, 81, 165)">]</span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    verbose</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token boolean">True</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain"></span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Set the associated prompt based upon the model version.</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#F5F5F5"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token keyword" style="color:rgb(0, 0, 255)">from</span><span class="token plain"> langchain</span><span class="token punctuation" style="color:rgb(4, 81, 165)">.</span><span class="token plain">chains</span><span class="token punctuation" style="color:rgb(4, 81, 165)">.</span><span class="token plain">prompt_selector </span><span class="token keyword" style="color:rgb(0, 0, 255)">import</span><span class="token plain"> ConditionalPromptSelector</span><br></span><span class="token-line" style="color:#000000"><span class="token plain"></span><span class="token keyword" style="color:rgb(0, 0, 255)">from</span><span class="token plain"> langchain_core</span><span class="token punctuation" style="color:rgb(4, 81, 165)">.</span><span class="token plain">prompts </span><span class="token keyword" style="color:rgb(0, 0, 255)">import</span><span class="token plain"> PromptTemplate</span><br></span><span class="token-line" style="color:#000000"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">DEFAULT_LLAMA_SEARCH_PROMPT </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> PromptTemplate</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    input_variables</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token punctuation" style="color:rgb(4, 81, 165)">[</span><span class="token string" style="color:rgb(163, 21, 21)">&quot;question&quot;</span><span class="token punctuation" style="color:rgb(4, 81, 165)">]</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    template</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token triple-quoted-string string" style="color:rgb(163, 21, 21)">&quot;&quot;&quot;&lt;&lt;SYS&gt;&gt; \n You are an assistant tasked with improving Google search \</span><br></span><span class="token-line" style="color:#000000"><span class="token triple-quoted-string string" style="color:rgb(163, 21, 21)">results. \n &lt;&lt;/SYS&gt;&gt; \n\n [INST] Generate THREE Google search queries that \</span><br></span><span class="token-line" style="color:#000000"><span class="token triple-quoted-string string" style="color:rgb(163, 21, 21)">are similar to this question. The output should be a numbered list of questions \</span><br></span><span class="token-line" style="color:#000000"><span class="token triple-quoted-string string" style="color:rgb(163, 21, 21)">and each should have a question mark at the end: \n\n {question} [/INST]&quot;&quot;&quot;</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain"></span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">DEFAULT_SEARCH_PROMPT </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> PromptTemplate</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    input_variables</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token punctuation" style="color:rgb(4, 81, 165)">[</span><span class="token string" style="color:rgb(163, 21, 21)">&quot;question&quot;</span><span class="token punctuation" style="color:rgb(4, 81, 165)">]</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    template</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token triple-quoted-string string" style="color:rgb(163, 21, 21)">&quot;&quot;&quot;You are an assistant tasked with improving Google search \</span><br></span><span class="token-line" style="color:#000000"><span class="token triple-quoted-string string" style="color:rgb(163, 21, 21)">results. Generate THREE Google search queries that are similar to \</span><br></span><span class="token-line" style="color:#000000"><span class="token triple-quoted-string string" style="color:rgb(163, 21, 21)">this question. The output should be a numbered list of questions and each \</span><br></span><span class="token-line" style="color:#000000"><span class="token triple-quoted-string string" style="color:rgb(163, 21, 21)">should have a question mark at the end: {question}&quot;&quot;&quot;</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain"></span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">QUESTION_PROMPT_SELECTOR </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> ConditionalPromptSelector</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    default_prompt</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain">DEFAULT_SEARCH_PROMPT</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    conditionals</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token punctuation" style="color:rgb(4, 81, 165)">[</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token keyword" style="color:rgb(0, 0, 255)">lambda</span><span class="token plain"> llm</span><span class="token punctuation" style="color:rgb(4, 81, 165)">:</span><span class="token plain"> </span><span class="token builtin" style="color:rgb(0, 112, 193)">isinstance</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token plain">llm</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"> LlamaCpp</span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"> DEFAULT_LLAMA_SEARCH_PROMPT</span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><span class="token punctuation" style="color:rgb(4, 81, 165)">]</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain"></span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">prompt </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> QUESTION_PROMPT_SELECTOR</span><span class="token punctuation" style="color:rgb(4, 81, 165)">.</span><span class="token plain">get_prompt</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token plain">llm</span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">prompt</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><div style="padding-top:1.3rem;background:var(--prism-background-color);color:var(--prism-color);margin-top:calc(-1 * var(--ifm-leading) - 5px);margin-bottom:var(--ifm-leading);box-shadow:var(--ifm-global-shadow-lw);border-bottom-left-radius:var(--ifm-code-border-radius);border-bottom-right-radius:var(--ifm-code-border-radius)"><b style="padding-left:0.65rem;margin-bottom:0.45rem;margin-right:0.5rem">API Reference:</b><span><a href="https://python.langchain.com/api_reference/langchain/chains/langchain.chains.prompt_selector.ConditionalPromptSelector.html">ConditionalPromptSelector</a> | </span><span><a href="https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.prompt.PromptTemplate.html">PromptTemplate</a></span></div>
<div class="language-output codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-output codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#F5F5F5"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">PromptTemplate(input_variables=[&#x27;question&#x27;], output_parser=None, partial_variables={}, template=&#x27;&lt;&lt;SYS&gt;&gt; \n You are an assistant tasked with improving Google search results. \n &lt;&lt;/SYS&gt;&gt; \n\n [INST] Generate THREE Google search queries that are similar to this question. The output should be a numbered list of questions and each should have a question mark at the end: \n\n {question} [/INST]&#x27;, template_format=&#x27;f-string&#x27;, validate_template=True)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#F5F5F5"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token comment" style="color:rgb(0, 128, 0)"># Chain</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">chain </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> prompt </span><span class="token operator" style="color:rgb(0, 0, 0)">|</span><span class="token plain"> llm</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">question </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(163, 21, 21)">&quot;What NFL team won the Super Bowl in the year that Justin Bieber was born?&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">chain</span><span class="token punctuation" style="color:rgb(4, 81, 165)">.</span><span class="token plain">invoke</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token punctuation" style="color:rgb(4, 81, 165)">{</span><span class="token string" style="color:rgb(163, 21, 21)">&quot;question&quot;</span><span class="token punctuation" style="color:rgb(4, 81, 165)">:</span><span class="token plain"> question</span><span class="token punctuation" style="color:rgb(4, 81, 165)">}</span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="language-output codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-output codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#F5F5F5"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">  Sure! Here are three similar search queries with a question mark at the end:</span><br></span><span class="token-line" style="color:#000000"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">1. Which NBA team did LeBron James lead to a championship in the year he was drafted?</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">2. Who won the Grammy Awards for Best New Artist and Best Female Pop Vocal Performance in the same year that Lady Gaga was born?</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">3. What MLB team did Babe Ruth play for when he hit 60 home runs in a single season?</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">``````output</span><br></span><span class="token-line" style="color:#000000"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">llama_print_timings:        load time = 14943.19 ms</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">llama_print_timings:      sample time =    72.93 ms /   101 runs   (    0.72 ms per token,  1384.87 tokens per second)</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">llama_print_timings: prompt eval time = 14942.95 ms /    93 tokens (  160.68 ms per token,     6.22 tokens per second)</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">llama_print_timings:        eval time =  3430.85 ms /   100 runs   (   34.31 ms per token,    29.15 tokens per second)</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">llama_print_timings:       total time = 18578.26 ms</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="language-output codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-output codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#F5F5F5"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">&#x27;  Sure! Here are three similar search queries with a question mark at the end:\n\n1. Which NBA team did LeBron James lead to a championship in the year he was drafted?\n2. Who won the Grammy Awards for Best New Artist and Best Female Pop Vocal Performance in the same year that Lady Gaga was born?\n3. What MLB team did Babe Ruth play for when he hit 60 home runs in a single season?&#x27;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>We also can use the LangChain Prompt Hub to fetch and / or store prompts that are model specific.</p>
<p>This will work with your <a href="https://docs.smith.langchain.com/" target="_blank" rel="noopener noreferrer">LangSmith API key</a>.</p>
<p>For example, <a href="https://smith.langchain.com/hub/rlm/rag-prompt-llama" target="_blank" rel="noopener noreferrer">here</a> is a prompt for RAG with LLaMA-specific tokens.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="use-cases">Use cases<a href="#use-cases" class="hash-link" aria-label="Direct link to Use cases" title="Direct link to Use cases">‚Äã</a></h2>
<p>Given an <code>llm</code> created from one of the models above, you can use it for <a href="/docs/how_to/#use-cases">many use cases</a>.</p>
<p>For example, you can implement a <a href="/docs/tutorials/rag/">RAG application</a> using the chat models demonstrated here.</p>
<p>In general, use cases for local LLMs can be driven by at least two factors:</p>
<ul>
<li><code>Privacy</code>: private data (e.g., journals, etc) that a user does not want to share</li>
<li><code>Cost</code>: text preprocessing (extraction/tagging), summarization, and agent simulations are token-use-intensive tasks</li>
</ul>
<p>In addition, <a href="https://blog.langchain.dev/using-langsmith-to-support-fine-tuning-of-open-source-llms/" target="_blank" rel="noopener noreferrer">here</a> is an overview on fine-tuning, which can utilize open-source LLMs.</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col"><a href="https://github.com/langchain-ai/langchain/edit/master/docs/docs/how_to/local_llms.ipynb" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/how_to/llm_token_usage_tracking/"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">How to track token usage for LLMs</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/how_to/logprobs/"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">How to get log probabilities</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#use-case" class="table-of-contents__link toc-highlight">Use case</a></li><li><a href="#overview" class="table-of-contents__link toc-highlight">Overview</a><ul><li><a href="#open-source-llms" class="table-of-contents__link toc-highlight">Open-source LLMs</a></li><li><a href="#inference" class="table-of-contents__link toc-highlight">Inference</a></li><li><a href="#formatting-prompts" class="table-of-contents__link toc-highlight">Formatting prompts</a></li></ul></li><li><a href="#quickstart" class="table-of-contents__link toc-highlight">Quickstart</a></li><li><a href="#environment" class="table-of-contents__link toc-highlight">Environment</a><ul><li><a href="#running-apple-silicon-gpu" class="table-of-contents__link toc-highlight">Running Apple silicon GPU</a></li></ul></li><li><a href="#llms" class="table-of-contents__link toc-highlight">LLMs</a><ul><li><a href="#ollama" class="table-of-contents__link toc-highlight">Ollama</a></li><li><a href="#llamacpp" class="table-of-contents__link toc-highlight">Llama.cpp</a></li><li><a href="#gpt4all" class="table-of-contents__link toc-highlight">GPT4All</a></li><li><a href="#llamafile" class="table-of-contents__link toc-highlight">llamafile</a></li></ul></li><li><a href="#prompts" class="table-of-contents__link toc-highlight">Prompts</a></li><li><a href="#use-cases" class="table-of-contents__link toc-highlight">Use cases</a></li></ul></div></div></div></div></main></div></div></div><footer class="footer"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://forum.langchain.com/" target="_blank" rel="noopener noreferrer" class="footer__link-item">LangChain Forum<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://twitter.com/LangChainAI" target="_blank" rel="noopener noreferrer" class="footer__link-item">Twitter<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">GitHub</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/langchain-ai" target="_blank" rel="noopener noreferrer" class="footer__link-item">Organization<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://github.com/langchain-ai/langchain" target="_blank" rel="noopener noreferrer" class="footer__link-item">Python<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://github.com/langchain-ai/langchainjs" target="_blank" rel="noopener noreferrer" class="footer__link-item">JS/TS<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://langchain.com" target="_blank" rel="noopener noreferrer" class="footer__link-item">Homepage<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://blog.langchain.dev" target="_blank" rel="noopener noreferrer" class="footer__link-item">Blog<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.youtube.com/@LangChain" target="_blank" rel="noopener noreferrer" class="footer__link-item">YouTube<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright ¬© 2025 LangChain, Inc.</div></div></div></footer></div>
</body>
</html>